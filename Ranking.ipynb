{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Expectations\n",
    "Build a search ranking model for bookable listings.\n",
    "\n",
    "## Metrics\n",
    "\n",
    "### Offline: Normalized Discounted Cumulative Gain (NDCG)\n",
    "NDCG is often used as a quality of search ranking results. It allows to calculate whether releavant search listings \n",
    "are appearing earlier  in the results. To compute NDCG for the overall search results with N queries, we take the mean of the respective NDCGs of all the N queries.\n",
    "\n",
    "### Online: Revenue\n",
    "In an online setting, the success could be measured by an increase in booking revenue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4033,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "import datetime\n",
    "from math import log, floor, radians, cos, sin, asin, sqrt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve, GridSearchCV,  ShuffleSplit\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, cohen_kappa_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# to see all the columns printed\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Data Import And Basic Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4034,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few potential issues could be already seen at this point\n",
    "1. missing values\n",
    "2. negative values in multiple columns\n",
    "3. very high max price, potential outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows\", df.shape[0])\n",
    "print(\"Number of cols\", df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Understanding Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "ax = sns.countplot(x=\"label\", data=df)\n",
    "plt.title('What is the action distribution in label (%)?')\n",
    "ax2=ax.twinx()\n",
    "ax2.yaxis.tick_left()\n",
    "ax.yaxis.tick_right()\n",
    "ax.yaxis.set_label_position('right')\n",
    "ax2.yaxis.set_label_position('left')\n",
    "ax2.set_ylabel('Frequency [%]')\n",
    "for p in ax.patches:\n",
    "    x=p.get_bbox().get_points()[:,0]\n",
    "    y=p.get_bbox().get_points()[1,1]\n",
    "    ax.annotate('{:.1f}%'.format(100.*y/df.label.count()), (x.mean(), y), \n",
    "            ha='center', va='bottom')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of all search results we have (13%) of listings with bookings.\n",
    "\n",
    "Initially I will work on the model to predict the probability of booking. Since click, host_contact can also indicate an interest from the user, later on I could look at the combined probability to book, contact_host, click with weights to improve the ranking score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4041,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['booked'] = np.where(df['label'] == 'book', 1, 0)\n",
    "df['clicked'] = np.where(df['label'] == 'click', 1, 0)\n",
    "df['contacted'] = np.where(df['label'] == 'host_contact', 1, 0)\n",
    "df['impression'] = np.where(df['label'] == 'impression', 1, 0)\n",
    "\n",
    "conditions = [\n",
    "    (df['label'] == 'book'),\n",
    "    (df['label'] == 'host_contact'),\n",
    "    (df['label'] == 'click'),\n",
    "    (df['label'] == 'impression')]\n",
    "\n",
    "choices = [1.0, 0.5, 0.3, 0]\n",
    "\n",
    "df['action'] = np.select(conditions, choices)\n",
    "#df = df.drop(columns = ['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.action.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do we know about search id?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many listings are in search?\n",
    "df1 = df.groupby(\"id_search\")[\"id_listing\"].nunique()\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of listings ranges from 1 to 18 with average of 2. I suspect that the lower  and upper bounds could be limited by the snapshot of the dataset and not necessary what \n",
    "user could see in particular search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many searches with bookings?\n",
    "df.id_search.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.id_user.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.id_listing.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4047,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.groupby([\"id_search\"]).agg({\"booked\": np.sum})\n",
    "df1_booked = df1[df1.booked != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2218 searches with bookings\n",
    "How many average listings in searches with bookings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_id_with_booking = df1_booked.index.tolist()\n",
    "df_with_bookings = df[df['id_search'].isin(search_id_with_booking)] \n",
    "df_with_bookings.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_bookings.loc[(df_with_bookings.id_search == '3b3a5ee9-6a4d-4cae-a7a2-caf9fb44e949')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_bookings = df[df['id_search'].isin(search_id_with_booking)] \n",
    "df1 = df_with_bookings.groupby(\"id_search\")[\"id_listing\"].nunique()\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In searches with bookings, there are on average 6 listings. For evaluation of NDCG @k, I will use the average k == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listings are unique within a specific search id, since only the last action on that listing is being recorded.\n",
    "# Lets look at the situation when the same user, acts on the same listing same day\n",
    "df1 = df.groupby(['id_user', 'id_listing', 'ds_search', \"label\"]).size().sort_values(ascending=False).reset_index(name='count')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The same user booked the same listing on the same day, we need to take a closer look.\n",
    "df.loc[(df.id_user == '99cd10f6ab7f9eacba5222c7179c882d') & (df.id_listing == 'f596a76ad5fb342fde248fb6ec07dcf2') & (df.ds_search == '11/22/18')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same listing was booked by the same person 4 times on the same day. For user those were different searches for the same timeframe, but different number of of guests in the query.\n",
    "\n",
    "At this point I will assume that if listing was booked by the same user on the same day, the listing is marked as 'book' in all searchers\n",
    "on that day.  Given that we are dealing with imbalanced dataset I am going to keep all those records nonetheless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above query contains the same listing, but listing_num_beds == 4 in 3 out of 4 rows and NaN in 1. At this point\n",
    "I will assume that NaN was a result of a logging problem. Therefore I think using median or KNN as imputer strategy might be reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are working with 7 days window of data. Calculating historic observation in this timeframe, might put some\n",
    "users observations outside of the data window, even for a single. day aggregations as the data might have been incomplete for upper and \n",
    "lower bound days.\n",
    "Therefore, the meaningful calculations that are unaffected by the time window are:\n",
    "    1. Days of the week\n",
    "    2. Time between checkin-checkout\n",
    "    3. Time between search query and checkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4053,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['search_date'] = pd.to_datetime(df['ds_search'])\n",
    "df['search_time_day_name'] = df.search_date.dt.day_name()\n",
    "df['checkin_date'] = pd.to_datetime(df['query_checkin'])\n",
    "df['checkin_date_day_name'] = df.checkin_date.dt.day_name()\n",
    "df['checkout_date'] = pd.to_datetime(df['query_checkout'])\n",
    "df['checkout_date_day_name'] = df.checkout_date.dt.day_name()\n",
    "df['checkin_checkout_days_between'] = (df.checkout_date - df.checkin_date).dt.days\n",
    "df['search_checkin_days_between'] = (df.checkin_date - df.search_date).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will drop the date column. Given the short timeframe, day name might carry out more. information than just dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4054,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['query_checkin', 'query_checkout', 'search_date', 'checkin_date', 'checkout_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Geo Coordinates And Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The search queries contain geo coordinates for search and listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4055,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1_booked = df[df.booked != 0]\n",
    "\n",
    "plt.figure(figsize = (15,8))\n",
    "plt.xlabel('Latitude')  \n",
    "plt.ylabel('Longitude')  \n",
    "  \n",
    "# displaying the title \n",
    "plt.title(\"Geo Coordinates Of Queries (Red), Listings (Blue), Listings With Bookings (Green)\", fontsize=14) \n",
    "\n",
    "l = plt.scatter(df['listing_lat'], df['listing_lng'], color='b')\n",
    "q = plt.scatter(df['query_center_lat'], df['query_center_lng'], color='r')\n",
    "b = plt.scatter(df1_booked['listing_lat'], df1_booked['listing_lng'], color='g')\n",
    "\n",
    "plt.legend((l,q,b),('Listings', 'Queries','Listings With Bookings'),scatterpoints=1, loc='lower right', ncol=1, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some listings are located further away from search centers and those listings did not result in booking. Distance between query center and listing geo coordine might be important in decision top book for a user. To capture that I will calculate distance between query search and listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4056,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    km = 6371* c\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4057,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['distance'] = df.apply(lambda row : haversine(row['query_center_lng'], row['query_center_lat'], row['listing_lng'],  row['listing_lat']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4058,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"query_center_lng_rad\"] = np.radians(df[\"query_center_lng\"])\n",
    "#df[\"query_center_lat_rad\"] = np.radians(df[\"query_center_lat\"])\n",
    "#df[\"listing_lng_rad\"] = np.radians(df[\"listing_lng\"])\n",
    "#df[\"listing_lat_rad\"] = np.radians(df[\"listing_lat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an advanced step, **TODO** I would reverse geocode lat, lng into postal code or convert them into a geohash, as neighbourhood might be a significant predictor.\n",
    "For now I'll just drop them and focus on the significance of distance alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4059,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['query_center_lng', 'query_center_lat', 'listing_lng', 'listing_lat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding User Action Per Day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset we are missing user-specific features. At the moment I will assume that rows in the dataset are being logged chronologically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cum_action_per_day will calculate user cumulative steps each day for each listing. On the same day, first chronoligical listing action will count as 0, than 1, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4060,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cum_user_action_per_day'] = df.groupby(['id_user', 'ds_search']).cumcount(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4061,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.030893642441661352\n"
     ]
    }
   ],
   "source": [
    "correlations = df.corr()['booked'].dropna().sort_values()\n",
    "print(correlations['cum_user_action_per_day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "\n",
    "msno.matrix(df.iloc[:, 0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data appears to be missing completely at random (MCAR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(df.iloc[:, 0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing data leakage columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4064,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['ds_search', 'ds_book', 'ds_contact'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4065,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_table(df):\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "                \n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "\n",
    "        return mis_val_table_ren_columns\n",
    "#missing_data = missing_values_table(df)\n",
    "#print(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4066,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_imputation(data, features):\n",
    "    from sklearn.impute import KNNImputer\n",
    "    imputer = KNNImputer(n_neighbors=2)\n",
    "    columns = features\n",
    "    for col in columns:\n",
    "        df[col] = imputer.fit_transform(df[[col]]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4067,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_imputation(data, features):\n",
    "    for feature_name in features:\n",
    "        missing_ids = data.loc[data[feature_name].isna(), :].index.values\n",
    "        imp_val = data[feature_name].median()\n",
    "        imputed_feature = [imp_val] * len(data.loc[missing_ids, feature_name])\n",
    "        data.loc[missing_ids, feature_name] = imputed_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4068,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complex_imputation(df, missing_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing KNN takes some time, for the sake of efficient time utilization, I will use simple median imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4069,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_imputation(df, missing_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4070,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 51 columns.\n",
      "There are 0 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Missing Values, % of Total Values]\n",
       "Index: []"
      ]
     },
     "execution_count": 4070,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Handling Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the total price can be correlated to the number of days between checkin and check out, \n",
    "lets first normalized that price by the number of days.\n",
    "From the dataframe description above it appears that listing_total_price might have potential outliers.\n",
    "Lets take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['listing_total_price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4072,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['listing_price_per_day'] = df['listing_total_price']/ df['checkin_checkout_days_between']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_bound = df['listing_price_per_day'].quantile(.99)\n",
    "print(upper_bound)\n",
    "\n",
    "lower_bound = df['listing_price_per_day'].quantile(.01)\n",
    "print(lower_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['listing_price_per_day'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['listing_price_per_day'] > upper_bound].booked.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average listing price per day is 114, but could go up to above $500K. This are the outliers that are likely to skew the picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['listing_price_per_day'] < lower_bound].booked.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The upper outliers did not result into any bookings. The lower outliers contain. booking with $0 price\n",
    "As we are focusing on revenue generation, I will remove those from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4077,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['listing_price_per_day'] < upper_bound) & (df['listing_price_per_day'] > lower_bound)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing Negative Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are negative value in the scale of ratings. I am going to adjust the scale to start with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4078,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['listing_location_rating'] = np.where(df['listing_location_rating'] < 0, 0, df['listing_location_rating'])\n",
    "df['listing_cleanliness_rating'] = np.where(df['listing_cleanliness_rating'] < 0, 0, df['listing_cleanliness_rating'])\n",
    "df['listing_checkin_rating'] = np.where(df['listing_checkin_rating'] < 0, 0, df['listing_checkin_rating'])\n",
    "df['listing_value_rating'] = np.where(df['listing_value_rating'] < 0, 0, df['listing_value_rating'])\n",
    "df['listing_communication_rating'] = np.where(df['listing_communication_rating'] < 0, 0, df['listing_communication_rating'])\n",
    "df['listing_accuracy_rating'] = np.where(df['listing_accuracy_rating'] < 0, 0, df['listing_accuracy_rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min max query price contains negative values that I assume are searches without min-max being set. \n",
    "Since there could be no negative price, I will adjust query_price_min to start with 0.\n",
    "And for max price if negative, I'll assume listing_total_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4079,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO evaluate: if user specifies min price as 0 that may carry additional information\n",
    "df['query_price_min'] = np.where(df['query_price_min'] < 0, 0, df['query_price_min'])\n",
    "df['query_price_max'] = np.where(df['query_price_max'] < 0, df['listing_total_price'], df['query_price_max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['listing_has_pro_pictures'] = df['listing_has_pro_pictures'].astype('int')\n",
    "df['listing_monthly_discount'] = df['listing_monthly_discount'].astype('int')\n",
    "df['listing_weekly_discount'] = df['listing_weekly_discount'].astype('int')\n",
    "df['listing_instant_bookable'] = df['listing_instant_bookable'].astype('int')\n",
    "\n",
    "df['action'] = df['action'].astype('float')\n",
    "\n",
    "categorical_cols  = ['query_market', 'search_time_day_name', 'checkin_date_day_name', 'checkout_date_day_name', 'listing_property_type', 'listing_room_type']\n",
    "df = pd.get_dummies(df, columns = categorical_cols)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Distributions & Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4082,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_feature(data, feature_name):\n",
    "    log_feature = data[feature_name].apply(lambda x: log((x+1)))\n",
    "    return log_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4083,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_features(data, col_names):\n",
    "    features = data[col_names]\n",
    "    scaler = StandardScaler().fit(features.values)\n",
    "    features = scaler.transform(features.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4084,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(data, col_names):\n",
    "    features = data[col_names]\n",
    "    scaler = MinMaxScaler().fit(features.values)\n",
    "    features = scaler.transform(features.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### listing_total_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4085,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['listing_price_per_day'] = df['listing_total_price']/ df['checkin_checkout_days_between']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['listing_price_per_day'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4087,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_price_per_day'] = log_feature(df, 'listing_price_per_day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_price_per_day'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4089,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = df.drop(columns=['listing_total_price', 'listing_price_per_day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['query_price_max'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4091,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_query_price_max'] = log_feature(df, 'query_price_max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_query_price_max'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4093,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = df.drop(columns=['query_price_max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['listing_cleaning_fee_per_day'] = df['listing_cleaning_fee']/ df['checkin_checkout_days_between']\n",
    "df['listing_cleaning_fee_per_day'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4095,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_cleaning_fee_per_day'] = log_feature(df, 'listing_cleaning_fee_per_day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4096,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = df.drop(columns=['listing_cleaning_fee_per_day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4098,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import statsmodels as sm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Create models from data\n",
    "def best_fit_distribution(data, bins=200, ax=None):\n",
    "    y, x = np.histogram(data, bins=bins, density=True)\n",
    "    x = (x + np.roll(x, -1))[:-1] / 2.0\n",
    "\n",
    "    # Distributions to check\n",
    "    DISTRIBUTIONS = [        \n",
    "        st.norm, st.lognorm, st.powerlaw, st.powerlognorm, st.uniform, st.expon\n",
    "    ]\n",
    "\n",
    "    # Best holders\n",
    "    best_distribution = st.norm\n",
    "    best_params = (0.0, 1.0)\n",
    "    best_sse = np.inf\n",
    "\n",
    "    # Estimate distribution parameters from data\n",
    "    for distribution in DISTRIBUTIONS:\n",
    "\n",
    "        # Try to fit the distribution\n",
    "        try:\n",
    "            # Ignore warnings from data that can't be fit\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings('ignore')\n",
    "                params = distribution.fit(data)\n",
    "\n",
    "                # Separate parts of parameters\n",
    "                arg = params[:-2]\n",
    "                loc = params[-2]\n",
    "                scale = params[-1]\n",
    "\n",
    "                # Calculate fitted PDF and error with fit in distribution\n",
    "                pdf = distribution.pdf(x, loc=loc, scale=scale, *arg)\n",
    "                sse = np.sum(np.power(y - pdf, 2.0))\n",
    "\n",
    "                # identify if this distribution is better\n",
    "                if best_sse > sse > 0:\n",
    "                    best_distribution = distribution\n",
    "                    best_params = params\n",
    "                    best_sse = sse\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error on: {} {}\".format(distribution, str(e)))\n",
    "            pass\n",
    "\n",
    "        #print(\"Distribution: {} | SSE: {}\".format(distribution, sse))\n",
    "\n",
    "    return best_distribution.name, best_sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4099,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in df.select_dtypes('number'):\n",
    "#    nm, pm = best_fit_distribution(df[col])\n",
    "#    print(col, nm, pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scaler data with a range of 0-1\n",
    "cols= [ \"query_price_min\", 'query_num_guests',  'query_num_children', 'query_radius', 'query_num_infants', 'listing_review_rating',\n",
    "           'listing_review_count', 'listing_num_beds', 'listing_num_bedrooms', 'listing_person_capacity', 'listing_location_rating','listing_cleanliness_rating',\n",
    "           'listing_checkin_rating',  'listing_value_rating', 'listing_communication_rating', 'listing_accuracy_rating',\n",
    "           'listing_occupancy_rate', 'listing_cleaning_fee', 'listing_num_books_90day', 'listing_monthly_price_factor',  'listing_weekly_price_factor',\n",
    "           'distance', 'listing_maximum_nights',  'listing_minimum_nights', 'listing_num_recent_reservations', 'checkin_checkout_days_between', \n",
    "           'search_checkin_days_between']\n",
    "\n",
    "standardize_features(df,cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all correlations and sort \n",
    "correlations = df.corr()['booked'].sort_values()\n",
    "print(correlations.head(15), '\\n')\n",
    "print(correlations.tail(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "listing_occupancy_rate  has the strongest positive correlation to book, others are ratings, listing_num_books_90day (which might have causality relation with ratings), listing_review_count, \n",
    "discounts and listing being instantly bookable.\n",
    "\n",
    "The negative correlations are listing_is_new, listing_person_capacity, listing_total_price, listing_num_beds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.02640913941836243"
      ]
     },
     "execution_count": 4133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations['listing_is_new']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Split Into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to split data by the id_search to ensure that the records that belong to the same id_search are not being separated into different datasets.\n",
    "\n",
    "In addition we are dealing with a heavily imbalanced dataset. To counter that with it I will downsample the majority class and upsample the minority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = df.groupby([\"id_search\"]).agg({\"booked\": np.sum, \"clicked\": np.sum, \"contacted\": np.sum, \"impression\": np.sum})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_booked = df_summary[df_summary.booked != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4105,
   "metadata": {},
   "outputs": [],
   "source": [
    "booked_ids = df_booked.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_bookings = df[df['id_search'].isin(booked_ids)]\n",
    "df_with_bookings.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_bookings_upsampled = resample(df_with_bookings, replace=True, n_samples=20000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_bookings_upsampled.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_impression_only = df_summary[(df_summary.booked == 0) & (df_summary.clicked == 0) & (df_summary.contacted == 0)]\n",
    "impression_only_ids = df_impression_only.index.values\n",
    "sample = np.random.choice(impression_only_ids.tolist(), floor(0.2*len(impression_only_ids)), False)\n",
    "sampled_impression_only_ids = df_summary.loc[sample].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_impression_only = df[df['id_search'].isin(sampled_impression_only_ids)] \n",
    "df_impression_only.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4111,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([df_with_bookings_upsampled, df_impression_only]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = pd.Series(new_df['id_search'].unique()).sample(10000, replace=True)\n",
    "train = new_df.loc[new_df['id_search'].isin(train_id)]\n",
    "test = new_df.loc[~new_df['id_search'].isin(train_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24073, 118)\n",
      "(14005, 118)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.booked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.booked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4117,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked_list = test['clicked']\n",
    "booked_list = test['booked']\n",
    "contacted_list = test['contacted']\n",
    "srchid_list = test['id_search']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4118,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['booked']\n",
    "X_train = train.drop(columns=['id_listing', 'id_search', 'label', 'id_user', 'booked', 'clicked', 'contacted', 'impression', 'action', 'id_search'])\n",
    "\n",
    "y_test = test['booked']\n",
    "X_test = test.drop(columns=['id_listing', 'id_search','label', 'id_user',  'booked', 'clicked', 'contacted', 'impression',  'action', 'id_search'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish a Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_results(name, test, pred):\n",
    "    f1score = f1_score(test, pred)\n",
    "    aucscore = roc_auc_score(test, pred)\n",
    "\n",
    "    confusion_Matrix = pd.DataFrame(\n",
    "        confusion_matrix(y_test, pred),\n",
    "        columns=['Predicted As No', 'Predicted As Yes'],\n",
    "        index=['True No', 'True Yes'])\n",
    "\n",
    "    print(classification_report(y_test, pred))\n",
    "    print(confusion_Matrix)\n",
    "    print('%s  f1_score =  %0.4f.' % (name, f1score))\n",
    "    print('%s  roc_auc_score =  %0.4f.' % (name, aucscore))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset contains categorical variables, I will use to establish a baseline model before any optimization.\n",
    "\n",
    "Model's optimirzation should focus on F1 score since it is important to capture all potential booking and be precise about what we are ranking first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, cohen_kappa_score, classification_report, recall_score, precision_score\n",
    "\n",
    "model1 = DecisionTreeClassifier(class_weight='balanced')\n",
    "model1.fit(X_train, y_train)\n",
    "y_pred1 =  model1.predict(X_test)\n",
    "print_model_results(\"DecisionTreeClassifier\", y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto ML With TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ipywidgets import IntProgress\n",
    "#from tpot import TPOTClassifier\n",
    "#tpot = TPOTClassifier(generations=2, population_size=20, cv=3, random_state=42, verbosity=3, scoring='roc_auc_ovr_weighted')\n",
    "#tpot.fit(X_train, y_train)\n",
    "#print(tpot.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model7 = ExtraTreesClassifier(n_estimators=100, max_features=0.55, \n",
    "                              min_samples_leaf=6, min_samples_split=11, criterion='entropy', bootstrap=False, \n",
    "                              class_weight='balanced', ccp_alpha=0.001, random_state=0)\n",
    "\n",
    "model7.fit(X_train, y_train)\n",
    "y_pred7 =  model7.predict(X_test)\n",
    "\n",
    "print_model_results(\"ExtraTreesClassifier\", y_test, y_pred7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importances = model2.feature_importances_\n",
    "std = np.std([model2.feature_importances_ for tree in model2.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%s. feature %d (%f)\" % ( X_train.columns[f],  indices[f], importances[indices[f]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>1 day 2 hours 29 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/Los_Angeles</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.32.0.5</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>9 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_i803030_8e2syj</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>4.722 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.8 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         1 day 2 hours 29 mins\n",
       "H2O_cluster_timezone:       America/Los_Angeles\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.32.0.5\n",
       "H2O_cluster_version_age:    9 days\n",
       "H2O_cluster_name:           H2O_from_python_i803030_8e2syj\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    4.722 Gb\n",
       "H2O_cluster_total_cores:    16\n",
       "H2O_cluster_allowed_cores:  16\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.8.8 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "h2o.init(\n",
    "    nthreads=-1,     \n",
    "    max_mem_size=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: || 100%\n",
      "Parse progress: || 100%\n",
      "Rows:24073\n",
      "Cols:110\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>index             </th><th>query_num_guests  </th><th>query_num_children  </th><th>query_num_infants  </th><th>query_radius      </th><th>query_price_min   </th><th>listing_is_new     </th><th>listing_instant_bookable  </th><th>listing_review_rating  </th><th>listing_review_count  </th><th>listing_num_beds  </th><th>listing_num_bedrooms  </th><th>listing_num_bathrooms  </th><th>listing_person_capacity  </th><th>listing_has_pro_pictures  </th><th>listing_num_recent_reservations  </th><th>listing_location_rating  </th><th>listing_cleanliness_rating  </th><th>listing_checkin_rating  </th><th>listing_value_rating  </th><th>listing_communication_rating  </th><th>listing_accuracy_rating  </th><th>listing_num_books_90day  </th><th>listing_occupancy_rate  </th><th>listing_monthly_discount  </th><th>listing_weekly_discount  </th><th>listing_cleaning_fee  </th><th>listing_monthly_price_factor  </th><th>listing_weekly_price_factor  </th><th>listing_minimum_nights  </th><th>listing_maximum_nights  </th><th>checkin_checkout_days_between  </th><th>search_checkin_days_between  </th><th>distance          </th><th>cum_user_action_per_day  </th><th>query_market_City A  </th><th>query_market_City B  </th><th>search_time_day_name_Friday  </th><th>search_time_day_name_Monday  </th><th>search_time_day_name_Sunday  </th><th>search_time_day_name_Thursday  </th><th>search_time_day_name_Tuesday  </th><th>search_time_day_name_Wednesday  </th><th>checkin_date_day_name_Friday  </th><th>checkin_date_day_name_Monday  </th><th>checkin_date_day_name_Saturday  </th><th>checkin_date_day_name_Sunday  </th><th>checkin_date_day_name_Thursday  </th><th>checkin_date_day_name_Tuesday  </th><th>checkin_date_day_name_Wednesday  </th><th>checkout_date_day_name_Friday  </th><th>checkout_date_day_name_Monday  </th><th>checkout_date_day_name_Saturday  </th><th>checkout_date_day_name_Sunday  </th><th>checkout_date_day_name_Thursday  </th><th>checkout_date_day_name_Tuesday  </th><th>checkout_date_day_name_Wednesday  </th><th>listing_property_type_0.0  </th><th>listing_property_type_1.0  </th><th>listing_property_type_2.0  </th><th>listing_property_type_3.0  </th><th>listing_property_type_4.0  </th><th>listing_property_type_5.0  </th><th>listing_property_type_6.0  </th><th>listing_property_type_8.0  </th><th>listing_property_type_9.0  </th><th>listing_property_type_10.0  </th><th>listing_property_type_11.0  </th><th>listing_property_type_15.0  </th><th>listing_property_type_16.0  </th><th>listing_property_type_17.0  </th><th>listing_property_type_19.0  </th><th>listing_property_type_22.0  </th><th>listing_property_type_23.0  </th><th>listing_property_type_24.0  </th><th>listing_property_type_29.0  </th><th>listing_property_type_32.0  </th><th>listing_property_type_33.0  </th><th>listing_property_type_34.0  </th><th>listing_property_type_35.0  </th><th>listing_property_type_36.0  </th><th>listing_property_type_37.0  </th><th>listing_property_type_38.0  </th><th>listing_property_type_40.0  </th><th>listing_property_type_41.0  </th><th>listing_property_type_42.0  </th><th>listing_property_type_43.0  </th><th>listing_property_type_44.0  </th><th>listing_property_type_45.0  </th><th>listing_property_type_47.0  </th><th>listing_property_type_50.0  </th><th>listing_property_type_52.0  </th><th>listing_property_type_53.0  </th><th>listing_property_type_54.0  </th><th>listing_property_type_56.0  </th><th>listing_property_type_57.0  </th><th>listing_property_type_58.0  </th><th>listing_property_type_60.0  </th><th>listing_property_type_63.0  </th><th>listing_property_type_64.0  </th><th>listing_property_type_65.0  </th><th>listing_property_type_67.0  </th><th>listing_property_type_70.0  </th><th>listing_room_type_Entire Home  </th><th>listing_room_type_Private Room  </th><th>listing_room_type_Shared Room  </th><th>log_price_per_day  </th><th>log_query_price_max  </th><th>log_cleaning_fee_per_day  </th><th>booked  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>int               </td><td>int               </td><td>int                 </td><td>int                </td><td>real              </td><td>int               </td><td>int                </td><td>int                       </td><td>real                   </td><td>int                   </td><td>int               </td><td>int                   </td><td>real                   </td><td>int                      </td><td>int                       </td><td>int                              </td><td>real                     </td><td>real                        </td><td>real                    </td><td>real                  </td><td>real                          </td><td>real                     </td><td>int                      </td><td>real                    </td><td>int                       </td><td>int                      </td><td>real                  </td><td>real                          </td><td>real                         </td><td>int                     </td><td>int                     </td><td>int                            </td><td>int                          </td><td>real              </td><td>int                      </td><td>int                  </td><td>int                  </td><td>int                          </td><td>int                          </td><td>int                          </td><td>int                            </td><td>int                           </td><td>int                             </td><td>int                           </td><td>int                           </td><td>int                             </td><td>int                           </td><td>int                             </td><td>int                            </td><td>int                              </td><td>int                            </td><td>int                            </td><td>int                              </td><td>int                            </td><td>int                              </td><td>int                             </td><td>int                               </td><td>int                        </td><td>int                        </td><td>int                        </td><td>int                        </td><td>int                        </td><td>int                        </td><td>int                        </td><td>int                        </td><td>int                        </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                         </td><td>int                            </td><td>int                             </td><td>int                            </td><td>real               </td><td>real                 </td><td>real                      </td><td>enum    </td></tr>\n",
       "<tr><td>mins   </td><td>2.0               </td><td>0.0               </td><td>0.0                 </td><td>0.0                </td><td>0.0               </td><td>0.0               </td><td>0.0                </td><td>0.0                       </td><td>0.0                    </td><td>0.0                   </td><td>0.0               </td><td>0.0                   </td><td>0.0                    </td><td>0.0                      </td><td>0.0                       </td><td>0.0                              </td><td>0.0                      </td><td>0.0                         </td><td>0.0                     </td><td>0.0                   </td><td>0.0                           </td><td>0.0                      </td><td>0.0                      </td><td>0.0                     </td><td>0.0                       </td><td>0.0                      </td><td>0.0                   </td><td>0.2206628190197833            </td><td>0.2991225699760877           </td><td>0.0                     </td><td>1.0                     </td><td>1.0                            </td><td>0.0                          </td><td>0.0               </td><td>0.0                      </td><td>0.0                  </td><td>0.0                  </td><td>0.0                          </td><td>0.0                          </td><td>0.0                          </td><td>0.0                            </td><td>0.0                           </td><td>0.0                             </td><td>0.0                           </td><td>0.0                           </td><td>0.0                             </td><td>0.0                           </td><td>0.0                             </td><td>0.0                            </td><td>0.0                              </td><td>0.0                            </td><td>0.0                            </td><td>0.0                              </td><td>0.0                            </td><td>0.0                              </td><td>0.0                             </td><td>0.0                               </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                            </td><td>0.0                             </td><td>0.0                            </td><td>1.3564317492220133 </td><td>1.3564317492220133   </td><td>0.0                       </td><td>        </td></tr>\n",
       "<tr><td>mean   </td><td>89548.65492460437 </td><td>2.463423752752049 </td><td>0.15232833464877665 </td><td>0.04486354006563366</td><td>11.898760613437966</td><td>4.3647239646076486</td><td>0.15639928550658413</td><td>0.6383500186931417        </td><td>3.7867642399368564     </td><td>23.715573464046848    </td><td>2.5845137706143726</td><td>1.4084243758567678    </td><td>1.474868109500271      </td><td>4.18601753001287         </td><td>0.06783533419183317       </td><td>0.02641964026087318              </td><td>3.790727652789436        </td><td>3.6931740530137547          </td><td>3.812921242005561       </td><td>3.6609608881776237    </td><td>3.8072399333984106            </td><td>3.7662239411706104       </td><td>5.870851161051806        </td><td>0.328046615620623       </td><td>0.595189631537407         </td><td>0.583433722427616        </td><td>33.233810885305516    </td><td>0.8144687894819371            </td><td>0.9180219812806373           </td><td>2.2831803265068777      </td><td>42241.65388609636       </td><td>7.18788684418228               </td><td>44.21048477547467            </td><td>5.505149097349404 </td><td>26.722053753167405       </td><td>0.7310264611805758   </td><td>0.26897353881942426  </td><td>0.1611764217172766           </td><td>0.23769368171810742          </td><td>0.16632742076184936          </td><td>0.15864246250986583            </td><td>0.13151663689610768           </td><td>0.1446433763967931              </td><td>0.2164665808166826            </td><td>0.12283471108711004           </td><td>0.16749054957836582             </td><td>0.11843143771029785           </td><td>0.1483404644207203              </td><td>0.10015369916503968            </td><td>0.12628255722178375              </td><td>0.1107464794583143             </td><td>0.1700245087857766             </td><td>0.10364308561458896              </td><td>0.18718065882939391            </td><td>0.13139201595148092              </td><td>0.14227557844888464             </td><td>0.15473767291156068               </td><td>0.00012462094462676026     </td><td>0.7211814065550617         </td><td>0.08366219415943173        </td><td>0.005234079674323932       </td><td>0.000996967557014082       </td><td>8.308062975117352e-05      </td><td>0.0                        </td><td>0.00041540314875586755     </td><td>4.154031487558676e-05      </td><td>0.0                         </td><td>0.0011215885016408423       </td><td>0.0                         </td><td>0.0002907822041291073       </td><td>0.0                         </td><td>4.154031487558676e-05       </td><td>0.0019108544842769907       </td><td>0.0012877497611431894       </td><td>4.154031487558675e-05       </td><td>4.154031487558676e-05       </td><td>0.0                         </td><td>0.002409338262784032        </td><td>0.0002492418892535205       </td><td>0.041291072986333235        </td><td>0.0034893864495492877       </td><td>0.048976031238316786        </td><td>0.000664645038009388        </td><td>0.007768038881734724        </td><td>4.154031487558676e-05       </td><td>0.001703152909899057        </td><td>0.0006646450380093881       </td><td>0.00012462094462676026      </td><td>0.005691023137955386        </td><td>0.05342084493000457         </td><td>4.154031487558676e-05       </td><td>4.154031487558676e-05       </td><td>0.00959581273626054         </td><td>0.000996967557014082        </td><td>0.0021185560586549244       </td><td>0.0                         </td><td>0.00012462094462676026      </td><td>0.0028662817264154864       </td><td>0.00033232251900469406      </td><td>4.154031487558676e-05       </td><td>0.0                         </td><td>0.0008723466123873219       </td><td>0.0                         </td><td>0.8068790761433972             </td><td>0.17766792672288456             </td><td>0.015452997133718274           </td><td>4.096030429226919  </td><td>5.394489839388954    </td><td>1.9244473532739839        </td><td>        </td></tr>\n",
       "<tr><td>maxs   </td><td>177582.0          </td><td>17.0              </td><td>5.0                 </td><td>3.0                </td><td>1487.1038291785862</td><td>961.0             </td><td>1.0                </td><td>1.0                       </td><td>5.0                    </td><td>317.0                 </td><td>50.0              </td><td>45.0                  </td><td>20.0                   </td><td>17.0                     </td><td>1.0                       </td><td>1.0                              </td><td>5.0                      </td><td>5.0                         </td><td>5.0                     </td><td>5.0                   </td><td>5.0                           </td><td>5.0                      </td><td>57.0                     </td><td>1.0097218623058477      </td><td>1.0                       </td><td>1.0                      </td><td>757.6091939752802     </td><td>1.0058714221822658            </td><td>1.0028725484238226           </td><td>89.0                    </td><td>1000000000.0            </td><td>274.0                          </td><td>460.0                        </td><td>1601.3298918875485</td><td>380.0                    </td><td>1.0                  </td><td>1.0                  </td><td>1.0                          </td><td>1.0                          </td><td>1.0                          </td><td>1.0                            </td><td>1.0                           </td><td>1.0                             </td><td>1.0                           </td><td>1.0                           </td><td>1.0                             </td><td>1.0                           </td><td>1.0                             </td><td>1.0                            </td><td>1.0                              </td><td>1.0                            </td><td>1.0                            </td><td>1.0                              </td><td>1.0                            </td><td>1.0                              </td><td>1.0                             </td><td>1.0                               </td><td>1.0                        </td><td>1.0                        </td><td>1.0                        </td><td>1.0                        </td><td>1.0                        </td><td>1.0                        </td><td>0.0                        </td><td>1.0                        </td><td>1.0                        </td><td>0.0                         </td><td>1.0                         </td><td>0.0                         </td><td>1.0                         </td><td>0.0                         </td><td>1.0                         </td><td>1.0                         </td><td>1.0                         </td><td>1.0                         </td><td>1.0                         </td><td>0.0                         </td><td>1.0                         </td><td>1.0                         </td><td>1.0                         </td><td>1.0                         </td><td>1.0                         </td><td>1.0                         </td><td>1.0                         </td><td>1.0                         </td><td>1.0                         </td><td>1.0                         </td><td>1.0                         </td><td>1.0                         </td><td>1.0                         </td><td>1.0                         </td><td>1.0                         </td><td>1.0                         </td><td>1.0                         </td><td>1.0                         </td><td>0.0                         </td><td>1.0                         </td><td>1.0                         </td><td>1.0                         </td><td>1.0                         </td><td>0.0                         </td><td>1.0                         </td><td>0.0                         </td><td>1.0                            </td><td>1.0                             </td><td>1.0                            </td><td>6.812431185207976  </td><td>20.790924486354804   </td><td>6.516676445403693         </td><td>        </td></tr>\n",
       "<tr><td>sigma  </td><td>51257.226659781474</td><td>1.7244556485292737</td><td>0.5010130977954912  </td><td>0.21527218667069944</td><td>43.45569488820929 </td><td>28.086664800176763</td><td>0.36324100814220595</td><td>0.48048815041877835       </td><td>1.9354963613574019     </td><td>37.772555283981944    </td><td>2.346963584372604 </td><td>1.08641975789883      </td><td>0.9113518969567831     </td><td>2.4784968675304033       </td><td>0.2514683448943669        </td><td>0.16038301468325813              </td><td>2.026904400010454        </td><td>1.990640810605844           </td><td>2.0375795281954403      </td><td>1.9675501738764312    </td><td>2.0352785506186692            </td><td>2.0175184381806144       </td><td>7.331307339683326        </td><td>0.3080763883487356      </td><td>0.4908655041279024        </td><td>0.4929999090163558       </td><td>21.645346709915636    </td><td>0.13043828091398788           </td><td>0.06526673731244854          </td><td>2.154359809670427       </td><td>6445173.545380392       </td><td>11.313112155307856             </td><td>46.5186171460228             </td><td>32.884176708406386</td><td>31.505813543558542       </td><td>0.4434353870766376   </td><td>0.44343538707663754  </td><td>0.3677012363654758           </td><td>0.42567936597380457          </td><td>0.37238202184359165          </td><td>0.3653499369424416             </td><td>0.3379715314164462            </td><td>0.35174821920226224             </td><td>0.41184444405852094           </td><td>0.32825420156074486           </td><td>0.3734210196241544              </td><td>0.32312500597581467           </td><td>0.355444537549221               </td><td>0.3002110584226498             </td><td>0.33217443687871834              </td><td>0.31382445391738134            </td><td>0.37566213204394666            </td><td>0.304803306616159                </td><td>0.3900645846065603             </td><td>0.3378356038254279               </td><td>0.34933981699149347             </td><td>0.3616619401319849                </td><td>0.011162911385928466       </td><td>0.4484274061845241         </td><td>0.27688628741473054        </td><td>0.07215885517778185        </td><td>0.03155970512347263        </td><td>0.009114668310601537       </td><td>0.0                        </td><td>0.02037763083643028        </td><td>0.006445177644998371       </td><td>0.0                         </td><td>0.03347203432255922         </td><td>0.0                         </td><td>0.017050211905205902        </td><td>0.0                         </td><td>0.006445177644998371        </td><td>0.04367244381215945         </td><td>0.03586286224717028         </td><td>0.006445177644998371        </td><td>0.006445177644998371        </td><td>0.0                         </td><td>0.04902686202072771         </td><td>0.015785756845022543        </td><td>0.19896674286469118         </td><td>0.05896910277577604         </td><td>0.21582241431754057         </td><td>0.025772676953367348        </td><td>0.08779531107698844         </td><td>0.006445177644998371        </td><td>0.041234970740981015        </td><td>0.025772676953367348        </td><td>0.011162911385928466        </td><td>0.07522546420501235         </td><td>0.22487587446356566         </td><td>0.006445177644998371        </td><td>0.006445177644998371        </td><td>0.09748911692418555         </td><td>0.03155970512347263         </td><td>0.045979947820442846        </td><td>0.0                         </td><td>0.011162911385928466        </td><td>0.05346199477554513         </td><td>0.01822706453370329         </td><td>0.006445177644998371        </td><td>0.0                         </td><td>0.029523242220672506        </td><td>0.0                         </td><td>0.39475524812661666            </td><td>0.382240897751037               </td><td>0.12334842537422383            </td><td>0.8549709713762716 </td><td>1.9987839093976085   </td><td>0.8740993285899626        </td><td>        </td></tr>\n",
       "<tr><td>zeros  </td><td>0                 </td><td>447               </td><td>21579               </td><td>23032              </td><td>2377              </td><td>22742             </td><td>20308              </td><td>8706                      </td><td>4905                   </td><td>4735                  </td><td>247               </td><td>2607                  </td><td>413                    </td><td>25                       </td><td>22440                     </td><td>23437                            </td><td>5300                     </td><td>5293                        </td><td>5299                    </td><td>5300                  </td><td>5298                          </td><td>5295                     </td><td>5418                     </td><td>3039                    </td><td>9745                      </td><td>10028                    </td><td>809                   </td><td>0                             </td><td>0                            </td><td>209                     </td><td>0                       </td><td>0                              </td><td>635                          </td><td>5388              </td><td>904                      </td><td>6475                 </td><td>17598                </td><td>20193                        </td><td>18351                        </td><td>20069                        </td><td>20254                          </td><td>20907                         </td><td>20591                           </td><td>18862                         </td><td>21116                         </td><td>20041                           </td><td>21222                         </td><td>20502                           </td><td>21662                          </td><td>21033                            </td><td>21407                          </td><td>19980                          </td><td>21578                            </td><td>19567                          </td><td>20910                            </td><td>20648                           </td><td>20348                             </td><td>24070                      </td><td>6712                       </td><td>22059                      </td><td>23947                      </td><td>24049                      </td><td>24071                      </td><td>24073                      </td><td>24063                      </td><td>24072                      </td><td>24073                       </td><td>24046                       </td><td>24073                       </td><td>24066                       </td><td>24073                       </td><td>24072                       </td><td>24027                       </td><td>24042                       </td><td>24072                       </td><td>24072                       </td><td>24073                       </td><td>24015                       </td><td>24067                       </td><td>23079                       </td><td>23989                       </td><td>22894                       </td><td>24057                       </td><td>23886                       </td><td>24072                       </td><td>24032                       </td><td>24057                       </td><td>24070                       </td><td>23936                       </td><td>22787                       </td><td>24072                       </td><td>24072                       </td><td>23842                       </td><td>24049                       </td><td>24022                       </td><td>24073                       </td><td>24070                       </td><td>24004                       </td><td>24065                       </td><td>24072                       </td><td>24073                       </td><td>24052                       </td><td>24073                       </td><td>4649                           </td><td>19796                           </td><td>23701                          </td><td>0                  </td><td>0                    </td><td>809                       </td><td>        </td></tr>\n",
       "<tr><td>missing</td><td>0                 </td><td>0                 </td><td>0                   </td><td>0                  </td><td>0                 </td><td>0                 </td><td>0                  </td><td>0                         </td><td>0                      </td><td>0                     </td><td>0                 </td><td>0                     </td><td>0                      </td><td>0                        </td><td>0                         </td><td>0                                </td><td>0                        </td><td>0                           </td><td>0                       </td><td>0                     </td><td>0                             </td><td>0                        </td><td>0                        </td><td>0                       </td><td>0                         </td><td>0                        </td><td>0                     </td><td>0                             </td><td>0                            </td><td>0                       </td><td>0                       </td><td>0                              </td><td>0                            </td><td>0                 </td><td>0                        </td><td>0                    </td><td>0                    </td><td>0                            </td><td>0                            </td><td>0                            </td><td>0                              </td><td>0                             </td><td>0                               </td><td>0                             </td><td>0                             </td><td>0                               </td><td>0                             </td><td>0                               </td><td>0                              </td><td>0                                </td><td>0                              </td><td>0                              </td><td>0                                </td><td>0                              </td><td>0                                </td><td>0                               </td><td>0                                 </td><td>0                          </td><td>0                          </td><td>0                          </td><td>0                          </td><td>0                          </td><td>0                          </td><td>0                          </td><td>0                          </td><td>0                          </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                           </td><td>0                              </td><td>0                               </td><td>0                              </td><td>0                  </td><td>0                    </td><td>0                         </td><td>0       </td></tr>\n",
       "<tr><td>0      </td><td>10746.0           </td><td>2.0               </td><td>0.0                 </td><td>0.0                </td><td>4.318174936245933 </td><td>0.0               </td><td>0.0                </td><td>1.0                       </td><td>4.72                   </td><td>8.0                   </td><td>2.0               </td><td>1.0                   </td><td>1.0                    </td><td>4.0                      </td><td>0.0                       </td><td>0.0                              </td><td>5.0                      </td><td>4.75                        </td><td>4.875                   </td><td>4.875                 </td><td>4.875                         </td><td>5.0                      </td><td>2.0                      </td><td>0.6102826670540885      </td><td>1.0                       </td><td>1.0                      </td><td>22.43705532635001     </td><td>0.9004473340359707            </td><td>0.9302188547578526           </td><td>1.0                     </td><td>16.0                    </td><td>2.0                            </td><td>7.0                          </td><td>1.5113994087240934</td><td>32.0                     </td><td>1.0                  </td><td>0.0                  </td><td>1.0                          </td><td>0.0                          </td><td>0.0                          </td><td>0.0                            </td><td>0.0                           </td><td>0.0                             </td><td>1.0                           </td><td>0.0                           </td><td>0.0                             </td><td>0.0                           </td><td>0.0                             </td><td>0.0                            </td><td>0.0                              </td><td>0.0                            </td><td>0.0                            </td><td>0.0                              </td><td>1.0                            </td><td>0.0                              </td><td>0.0                             </td><td>0.0                               </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>1.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>1.0                            </td><td>0.0                             </td><td>0.0                            </td><td>3.856803011367134  </td><td>4.539326226196539    </td><td>2.502953460655889         </td><td>1       </td></tr>\n",
       "<tr><td>1      </td><td>70114.0           </td><td>2.0               </td><td>0.0                 </td><td>0.0                </td><td>23.79201476276368 </td><td>0.0               </td><td>0.0                </td><td>0.0                       </td><td>4.931034599999999      </td><td>6.0                   </td><td>2.0               </td><td>1.0                   </td><td>1.0                    </td><td>4.0                      </td><td>0.0                       </td><td>0.0                              </td><td>4.983051000000001        </td><td>4.8644066                   </td><td>4.983051000000001       </td><td>4.7966104000000005    </td><td>4.9661016                     </td><td>4.9491525                </td><td>21.0                     </td><td>0.6341820586775567      </td><td>1.0                       </td><td>1.0                      </td><td>39.17498091386595     </td><td>0.6999489214785828            </td><td>0.8999750102238209           </td><td>1.0                     </td><td>90.0                    </td><td>2.0                            </td><td>21.0                         </td><td>5.580430950169008 </td><td>12.0                     </td><td>1.0                  </td><td>0.0                  </td><td>0.0                          </td><td>1.0                          </td><td>0.0                          </td><td>0.0                            </td><td>0.0                           </td><td>0.0                             </td><td>0.0                           </td><td>1.0                           </td><td>0.0                             </td><td>0.0                           </td><td>0.0                             </td><td>0.0                            </td><td>0.0                              </td><td>0.0                            </td><td>0.0                            </td><td>0.0                              </td><td>0.0                            </td><td>0.0                              </td><td>0.0                             </td><td>1.0                               </td><td>0.0                        </td><td>1.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>1.0                            </td><td>0.0                             </td><td>0.0                            </td><td>3.95727925182764   </td><td>4.248495242049359    </td><td>3.024683631966698         </td><td>0       </td></tr>\n",
       "<tr><td>2      </td><td>154975.0          </td><td>3.0               </td><td>0.0                 </td><td>0.0                </td><td>25.03837687483233 </td><td>0.0               </td><td>1.0                </td><td>1.0                       </td><td>0.0                    </td><td>0.0                   </td><td>2.0               </td><td>2.0                   </td><td>3.0                    </td><td>4.0                      </td><td>0.0                       </td><td>0.0                              </td><td>0.0                      </td><td>0.0                         </td><td>0.0                     </td><td>0.0                   </td><td>0.0                           </td><td>0.0                      </td><td>0.0                      </td><td>0.0001240717744834      </td><td>0.0                       </td><td>0.0                      </td><td>32.656440936562845    </td><td>0.8114367506025689            </td><td>0.9196054670260624           </td><td>2.0                     </td><td>1125.0                  </td><td>4.0                            </td><td>69.0                         </td><td>4.896723057571955 </td><td>0.0                      </td><td>1.0                  </td><td>0.0                  </td><td>0.0                          </td><td>0.0                          </td><td>0.0                          </td><td>1.0                            </td><td>0.0                           </td><td>0.0                             </td><td>0.0                           </td><td>0.0                           </td><td>0.0                             </td><td>0.0                           </td><td>0.0                             </td><td>0.0                            </td><td>1.0                              </td><td>0.0                            </td><td>0.0                            </td><td>0.0                              </td><td>1.0                            </td><td>0.0                              </td><td>0.0                             </td><td>0.0                               </td><td>0.0                        </td><td>1.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>1.0                            </td><td>0.0                             </td><td>0.0                            </td><td>3.7757075168132297 </td><td>5.144661752166551    </td><td>2.2152947935608815        </td><td>0       </td></tr>\n",
       "<tr><td>3      </td><td>147033.0          </td><td>2.0               </td><td>0.0                 </td><td>0.0                </td><td>0.0               </td><td>0.0               </td><td>0.0                </td><td>1.0                       </td><td>4.7419353              </td><td>62.0                  </td><td>2.0               </td><td>1.0                   </td><td>1.0                    </td><td>4.0                      </td><td>0.0                       </td><td>0.0                              </td><td>5.0                      </td><td>4.629032                    </td><td>4.918032599999999       </td><td>4.7377048             </td><td>4.918032599999999             </td><td>4.6885247                </td><td>10.0                     </td><td>0.4101967551239671      </td><td>0.0                       </td><td>0.0                      </td><td>44.61542518826752     </td><td>0.9979459023497012            </td><td>0.9989950484253092           </td><td>1.0                     </td><td>1125.0                  </td><td>5.0                            </td><td>23.0                         </td><td>1.1119492664451645</td><td>29.0                     </td><td>1.0                  </td><td>0.0                  </td><td>0.0                          </td><td>1.0                          </td><td>0.0                          </td><td>0.0                            </td><td>0.0                           </td><td>0.0                             </td><td>0.0                           </td><td>0.0                           </td><td>0.0                             </td><td>0.0                           </td><td>0.0                             </td><td>0.0                            </td><td>1.0                              </td><td>0.0                            </td><td>1.0                            </td><td>0.0                              </td><td>0.0                            </td><td>0.0                              </td><td>0.0                             </td><td>0.0                               </td><td>0.0                        </td><td>1.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>1.0                            </td><td>0.0                             </td><td>0.0                            </td><td>4.12431100541663   </td><td>6.606650186198215    </td><td>2.2948638646478283        </td><td>0       </td></tr>\n",
       "<tr><td>4      </td><td>75145.0           </td><td>3.0               </td><td>0.0                 </td><td>0.0                </td><td>0.6653234004494555</td><td>0.0               </td><td>1.0                </td><td>0.0                       </td><td>0.0                    </td><td>0.0                   </td><td>1.0               </td><td>1.0                   </td><td>1.0                    </td><td>4.0                      </td><td>0.0                       </td><td>0.0                              </td><td>0.0                      </td><td>0.0                         </td><td>0.0                     </td><td>0.0                   </td><td>0.0                           </td><td>0.0                      </td><td>0.0                      </td><td>0.0008769521839053      </td><td>0.0                       </td><td>0.0                      </td><td>29.21975923525358     </td><td>0.8114367506025689            </td><td>0.9196054670260624           </td><td>2.0                     </td><td>30.0                    </td><td>2.0                            </td><td>12.0                         </td><td>0.0               </td><td>33.0                     </td><td>1.0                  </td><td>0.0                  </td><td>0.0                          </td><td>0.0                          </td><td>0.0                          </td><td>1.0                            </td><td>0.0                           </td><td>0.0                             </td><td>0.0                           </td><td>0.0                           </td><td>0.0                             </td><td>0.0                           </td><td>0.0                             </td><td>1.0                            </td><td>0.0                              </td><td>0.0                            </td><td>0.0                            </td><td>0.0                              </td><td>0.0                            </td><td>1.0                              </td><td>0.0                             </td><td>0.0                               </td><td>0.0                        </td><td>1.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>1.0                            </td><td>0.0                             </td><td>0.0                            </td><td>5.634620343761204  </td><td>6.325979910931743    </td><td>2.7479040226223184        </td><td>0       </td></tr>\n",
       "<tr><td>5      </td><td>81886.0           </td><td>1.0               </td><td>0.0                 </td><td>0.0                </td><td>26.63105173827488 </td><td>0.0               </td><td>0.0                </td><td>0.0                       </td><td>4.72                   </td><td>55.0                  </td><td>1.0               </td><td>1.0                   </td><td>1.0                    </td><td>4.0                      </td><td>0.0                       </td><td>0.0                              </td><td>4.946429                 </td><td>4.892857                    </td><td>4.964286                </td><td>4.892857              </td><td>4.8727274000000005            </td><td>4.909091                 </td><td>21.0                     </td><td>0.1814637493460498      </td><td>0.0                       </td><td>0.0                      </td><td>19.13995762156093     </td><td>0.8114367506025689            </td><td>0.9196054670260624           </td><td>1.0                     </td><td>30.0                    </td><td>2.0                            </td><td>7.0                          </td><td>6.749823455485879 </td><td>6.0                      </td><td>1.0                  </td><td>0.0                  </td><td>0.0                          </td><td>0.0                          </td><td>0.0                          </td><td>0.0                            </td><td>1.0                           </td><td>0.0                             </td><td>0.0                           </td><td>0.0                           </td><td>0.0                             </td><td>0.0                           </td><td>0.0                             </td><td>1.0                            </td><td>0.0                              </td><td>0.0                            </td><td>0.0                            </td><td>0.0                              </td><td>0.0                            </td><td>1.0                              </td><td>0.0                             </td><td>0.0                               </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>1.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>1.0                            </td><td>0.0                             </td><td>0.0                            </td><td>4.179204050419408  </td><td>3.9889840465642745   </td><td>2.358017795223606         </td><td>0       </td></tr>\n",
       "<tr><td>6      </td><td>175602.0          </td><td>1.0               </td><td>0.0                 </td><td>0.0                </td><td>4.451430947355603 </td><td>0.0               </td><td>0.0                </td><td>1.0                       </td><td>4.825                  </td><td>40.0                  </td><td>1.0               </td><td>0.0                   </td><td>1.0                    </td><td>2.0                      </td><td>0.0                       </td><td>0.0                              </td><td>4.9512196                </td><td>4.707317                    </td><td>4.8292685               </td><td>4.780488              </td><td>4.878049                      </td><td>4.878049                 </td><td>14.0                     </td><td>0.8222812370933194      </td><td>0.0                       </td><td>0.0                      </td><td>30.37069081625847     </td><td>0.8114367506025689            </td><td>0.9196054670260624           </td><td>1.0                     </td><td>1125.0                  </td><td>1.0                            </td><td>11.0                         </td><td>1.1119492664455182</td><td>5.0                      </td><td>1.0                  </td><td>0.0                  </td><td>0.0                          </td><td>1.0                          </td><td>0.0                          </td><td>0.0                            </td><td>0.0                           </td><td>0.0                             </td><td>1.0                           </td><td>0.0                           </td><td>0.0                             </td><td>0.0                           </td><td>0.0                             </td><td>0.0                            </td><td>0.0                              </td><td>0.0                            </td><td>0.0                            </td><td>1.0                              </td><td>0.0                            </td><td>0.0                              </td><td>0.0                             </td><td>0.0                               </td><td>0.0                        </td><td>1.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>1.0                            </td><td>0.0                             </td><td>0.0                            </td><td>4.4462401277044235 </td><td>4.356708826689592    </td><td>3.4458740435176063        </td><td>0       </td></tr>\n",
       "<tr><td>7      </td><td>57749.0           </td><td>3.0               </td><td>0.0                 </td><td>0.0                </td><td>1.4028893538259206</td><td>0.0               </td><td>0.0                </td><td>1.0                       </td><td>4.591837               </td><td>49.0                  </td><td>1.0               </td><td>0.0                   </td><td>1.0                    </td><td>4.0                      </td><td>0.0                       </td><td>0.0                              </td><td>4.914893599999999        </td><td>4.3673470000000005          </td><td>5.0                     </td><td>4.8297873             </td><td>4.893617                      </td><td>4.8541665                </td><td>16.0                     </td><td>0.6854568874654811      </td><td>1.0                       </td><td>1.0                      </td><td>7.9144698680218335    </td><td>0.6601338982723994            </td><td>0.9500655087063056           </td><td>2.0                     </td><td>90.0                    </td><td>2.0                            </td><td>91.0                         </td><td>0.0               </td><td>16.0                     </td><td>1.0                  </td><td>0.0                  </td><td>1.0                          </td><td>0.0                          </td><td>0.0                          </td><td>0.0                            </td><td>0.0                           </td><td>0.0                             </td><td>1.0                           </td><td>0.0                           </td><td>0.0                             </td><td>0.0                           </td><td>0.0                             </td><td>0.0                            </td><td>0.0                              </td><td>0.0                            </td><td>0.0                            </td><td>0.0                              </td><td>1.0                            </td><td>0.0                              </td><td>0.0                             </td><td>0.0                               </td><td>0.0                        </td><td>1.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>1.0                            </td><td>0.0                             </td><td>0.0                            </td><td>3.738726835848967  </td><td>4.007333185232471    </td><td>1.6008481123093294        </td><td>0       </td></tr>\n",
       "<tr><td>8      </td><td>72950.0           </td><td>1.0               </td><td>0.0                 </td><td>0.0                </td><td>24.23908406023151 </td><td>0.0               </td><td>0.0                </td><td>0.0                       </td><td>4.769231               </td><td>13.0                  </td><td>3.0               </td><td>0.0                   </td><td>2.0                    </td><td>6.0                      </td><td>0.0                       </td><td>0.0                              </td><td>5.0                      </td><td>4.6153846                   </td><td>4.923076999999999       </td><td>4.769231              </td><td>4.6923075                     </td><td>4.923076999999999        </td><td>14.0                     </td><td>0.5769298799687599      </td><td>0.0                       </td><td>0.0                      </td><td>0.0                   </td><td>0.8114367506025689            </td><td>0.9196054670260624           </td><td>2.0                     </td><td>1124.0                  </td><td>4.0                            </td><td>0.0                          </td><td>3.058010871727591 </td><td>7.0                      </td><td>0.0                  </td><td>1.0                  </td><td>0.0                          </td><td>1.0                          </td><td>0.0                          </td><td>0.0                            </td><td>0.0                           </td><td>0.0                             </td><td>0.0                           </td><td>1.0                           </td><td>0.0                             </td><td>0.0                           </td><td>0.0                             </td><td>0.0                            </td><td>0.0                              </td><td>1.0                            </td><td>0.0                            </td><td>0.0                              </td><td>0.0                            </td><td>0.0                              </td><td>0.0                             </td><td>0.0                               </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>1.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>1.0                            </td><td>0.0                             </td><td>0.0                            </td><td>3.7662910095495015 </td><td>5.135079745968927    </td><td>0.0                       </td><td>0       </td></tr>\n",
       "<tr><td>9      </td><td>148180.0          </td><td>3.0               </td><td>0.0                 </td><td>0.0                </td><td>2.6359993678715963</td><td>0.0               </td><td>0.0                </td><td>1.0                       </td><td>4.72                   </td><td>15.0                  </td><td>4.0               </td><td>3.0                   </td><td>2.0                    </td><td>5.0                      </td><td>0.0                       </td><td>0.0                              </td><td>5.0                      </td><td>4.923076999999999           </td><td>5.0                     </td><td>4.769231              </td><td>5.0                           </td><td>4.923076999999999        </td><td>2.0                      </td><td>0.504189228182764       </td><td>0.0                       </td><td>0.0                      </td><td>39.59706193939404     </td><td>0.8114367506025689            </td><td>0.9196054670260624           </td><td>2.0                     </td><td>1125.0                  </td><td>4.0                            </td><td>1.0                          </td><td>1.5084428911096464</td><td>2.0                      </td><td>0.0                  </td><td>1.0                  </td><td>0.0                          </td><td>0.0                          </td><td>0.0                          </td><td>1.0                            </td><td>0.0                           </td><td>0.0                             </td><td>1.0                           </td><td>0.0                           </td><td>0.0                             </td><td>0.0                           </td><td>0.0                             </td><td>0.0                            </td><td>0.0                              </td><td>0.0                            </td><td>0.0                            </td><td>0.0                              </td><td>0.0                            </td><td>0.0                              </td><td>1.0                             </td><td>0.0                               </td><td>0.0                        </td><td>1.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                        </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>0.0                         </td><td>1.0                            </td><td>0.0                             </td><td>0.0                            </td><td>4.663466225307875  </td><td>6.042660158209485    </td><td>2.388695400253366         </td><td>0       </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = X_train.columns.tolist()\n",
    "X_y_train_h = h2o.H2OFrame(pd.concat([X_train, y_train], axis='columns'))\n",
    "X_y_train_h['booked'] = X_y_train_h['booked'].asfactor()\n",
    "\n",
    "X_y_test_h = h2o.H2OFrame(pd.concat([X_test, y_test], axis='columns'))\n",
    "X_y_train_h.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: || 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20210325_233034   </td><td style=\"text-align: right;\"> 0.121844</td><td style=\"text-align: right;\">0.897859</td><td style=\"text-align: right;\">0.787611</td><td style=\"text-align: right;\">              0.154314</td><td style=\"text-align: right;\">0.163606</td><td style=\"text-align: right;\">0.0267669</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20210325_233034</td><td style=\"text-align: right;\"> 0.122612</td><td style=\"text-align: right;\">0.897968</td><td style=\"text-align: right;\">0.787019</td><td style=\"text-align: right;\">              0.154733</td><td style=\"text-align: right;\">0.164293</td><td style=\"text-align: right;\">0.0269923</td></tr>\n",
       "<tr><td>GBM_4_AutoML_20210325_233034                       </td><td style=\"text-align: right;\"> 0.140589</td><td style=\"text-align: right;\">0.887192</td><td style=\"text-align: right;\">0.778689</td><td style=\"text-align: right;\">              0.154991</td><td style=\"text-align: right;\">0.168322</td><td style=\"text-align: right;\">0.0283324</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210325_233034_model_4         </td><td style=\"text-align: right;\"> 0.140678</td><td style=\"text-align: right;\">0.88841 </td><td style=\"text-align: right;\">0.782913</td><td style=\"text-align: right;\">              0.154459</td><td style=\"text-align: right;\">0.164916</td><td style=\"text-align: right;\">0.0271972</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20210325_233034                       </td><td style=\"text-align: right;\"> 0.142548</td><td style=\"text-align: right;\">0.883521</td><td style=\"text-align: right;\">0.775868</td><td style=\"text-align: right;\">              0.156468</td><td style=\"text-align: right;\">0.17241 </td><td style=\"text-align: right;\">0.0297253</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210325_233034_model_10        </td><td style=\"text-align: right;\"> 0.143039</td><td style=\"text-align: right;\">0.883234</td><td style=\"text-align: right;\">0.773234</td><td style=\"text-align: right;\">              0.156491</td><td style=\"text-align: right;\">0.173178</td><td style=\"text-align: right;\">0.0299908</td></tr>\n",
       "<tr><td>GBM_2_AutoML_20210325_233034                       </td><td style=\"text-align: right;\"> 0.144275</td><td style=\"text-align: right;\">0.88075 </td><td style=\"text-align: right;\">0.774766</td><td style=\"text-align: right;\">              0.155658</td><td style=\"text-align: right;\">0.173871</td><td style=\"text-align: right;\">0.0302311</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210325_233034_model_2         </td><td style=\"text-align: right;\"> 0.144414</td><td style=\"text-align: right;\">0.879653</td><td style=\"text-align: right;\">0.773908</td><td style=\"text-align: right;\">              0.154474</td><td style=\"text-align: right;\">0.168712</td><td style=\"text-align: right;\">0.0284639</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210325_233034_model_9         </td><td style=\"text-align: right;\"> 0.145872</td><td style=\"text-align: right;\">0.88462 </td><td style=\"text-align: right;\">0.779958</td><td style=\"text-align: right;\">              0.154147</td><td style=\"text-align: right;\">0.168192</td><td style=\"text-align: right;\">0.0282885</td></tr>\n",
       "<tr><td>GBM_5_AutoML_20210325_233034                       </td><td style=\"text-align: right;\"> 0.146702</td><td style=\"text-align: right;\">0.879871</td><td style=\"text-align: right;\">0.773762</td><td style=\"text-align: right;\">              0.154335</td><td style=\"text-align: right;\">0.173673</td><td style=\"text-align: right;\">0.0301622</td></tr>\n",
       "<tr><td>GBM_1_AutoML_20210325_233034                       </td><td style=\"text-align: right;\"> 0.146997</td><td style=\"text-align: right;\">0.882852</td><td style=\"text-align: right;\">0.766053</td><td style=\"text-align: right;\">              0.158023</td><td style=\"text-align: right;\">0.180248</td><td style=\"text-align: right;\">0.0324895</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20210325_233034_model_5     </td><td style=\"text-align: right;\"> 0.148571</td><td style=\"text-align: right;\">0.876078</td><td style=\"text-align: right;\">0.773943</td><td style=\"text-align: right;\">              0.159779</td><td style=\"text-align: right;\">0.180007</td><td style=\"text-align: right;\">0.0324027</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210325_233034_model_7         </td><td style=\"text-align: right;\"> 0.151242</td><td style=\"text-align: right;\">0.877622</td><td style=\"text-align: right;\">0.775767</td><td style=\"text-align: right;\">              0.155302</td><td style=\"text-align: right;\">0.17221 </td><td style=\"text-align: right;\">0.0296562</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20210325_233034_model_4     </td><td style=\"text-align: right;\"> 0.153499</td><td style=\"text-align: right;\">0.878672</td><td style=\"text-align: right;\">0.76769 </td><td style=\"text-align: right;\">              0.158952</td><td style=\"text-align: right;\">0.179139</td><td style=\"text-align: right;\">0.0320908</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20210325_233034_model_2     </td><td style=\"text-align: right;\"> 0.154695</td><td style=\"text-align: right;\">0.876804</td><td style=\"text-align: right;\">0.770517</td><td style=\"text-align: right;\">              0.161727</td><td style=\"text-align: right;\">0.178242</td><td style=\"text-align: right;\">0.0317703</td></tr>\n",
       "<tr><td>XGBoost_1_AutoML_20210325_233034                   </td><td style=\"text-align: right;\"> 0.158744</td><td style=\"text-align: right;\">0.875606</td><td style=\"text-align: right;\">0.762845</td><td style=\"text-align: right;\">              0.159052</td><td style=\"text-align: right;\">0.179047</td><td style=\"text-align: right;\">0.0320579</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20210325_233034_model_1     </td><td style=\"text-align: right;\"> 0.160464</td><td style=\"text-align: right;\">0.874665</td><td style=\"text-align: right;\">0.757976</td><td style=\"text-align: right;\">              0.168524</td><td style=\"text-align: right;\">0.185258</td><td style=\"text-align: right;\">0.0343205</td></tr>\n",
       "<tr><td>XGBoost_3_AutoML_20210325_233034                   </td><td style=\"text-align: right;\"> 0.162239</td><td style=\"text-align: right;\">0.869622</td><td style=\"text-align: right;\">0.755238</td><td style=\"text-align: right;\">              0.16387 </td><td style=\"text-align: right;\">0.183866</td><td style=\"text-align: right;\">0.0338068</td></tr>\n",
       "<tr><td>DRF_1_AutoML_20210325_233034                       </td><td style=\"text-align: right;\"> 0.163019</td><td style=\"text-align: right;\">0.894748</td><td style=\"text-align: right;\">0.780736</td><td style=\"text-align: right;\">              0.158553</td><td style=\"text-align: right;\">0.194573</td><td style=\"text-align: right;\">0.0378588</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210325_233034_model_11        </td><td style=\"text-align: right;\"> 0.163047</td><td style=\"text-align: right;\">0.883961</td><td style=\"text-align: right;\">0.753751</td><td style=\"text-align: right;\">              0.183124</td><td style=\"text-align: right;\">0.200559</td><td style=\"text-align: right;\">0.0402237</td></tr>\n",
       "<tr><td>XGBoost_2_AutoML_20210325_233034                   </td><td style=\"text-align: right;\"> 0.163413</td><td style=\"text-align: right;\">0.869157</td><td style=\"text-align: right;\">0.757803</td><td style=\"text-align: right;\">              0.161414</td><td style=\"text-align: right;\">0.184952</td><td style=\"text-align: right;\">0.0342074</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20210325_233034_model_6     </td><td style=\"text-align: right;\"> 0.16767 </td><td style=\"text-align: right;\">0.875029</td><td style=\"text-align: right;\">0.739836</td><td style=\"text-align: right;\">              0.182932</td><td style=\"text-align: right;\">0.200502</td><td style=\"text-align: right;\">0.040201 </td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20210325_233034_model_7     </td><td style=\"text-align: right;\"> 0.176233</td><td style=\"text-align: right;\">0.868761</td><td style=\"text-align: right;\">0.710866</td><td style=\"text-align: right;\">              0.198489</td><td style=\"text-align: right;\">0.208514</td><td style=\"text-align: right;\">0.0434782</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210325_233034_model_1         </td><td style=\"text-align: right;\"> 0.180663</td><td style=\"text-align: right;\">0.86403 </td><td style=\"text-align: right;\">0.702642</td><td style=\"text-align: right;\">              0.207294</td><td style=\"text-align: right;\">0.212609</td><td style=\"text-align: right;\">0.0452028</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20210325_233034_model_3     </td><td style=\"text-align: right;\"> 0.183155</td><td style=\"text-align: right;\">0.86479 </td><td style=\"text-align: right;\">0.694627</td><td style=\"text-align: right;\">              0.209804</td><td style=\"text-align: right;\">0.214673</td><td style=\"text-align: right;\">0.0460845</td></tr>\n",
       "<tr><td>XRT_1_AutoML_20210325_233034                       </td><td style=\"text-align: right;\"> 0.198674</td><td style=\"text-align: right;\">0.884993</td><td style=\"text-align: right;\">0.767848</td><td style=\"text-align: right;\">              0.168973</td><td style=\"text-align: right;\">0.220688</td><td style=\"text-align: right;\">0.0487031</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210325_233034_model_6         </td><td style=\"text-align: right;\"> 0.209165</td><td style=\"text-align: right;\">0.854969</td><td style=\"text-align: right;\">0.612648</td><td style=\"text-align: right;\">              0.240779</td><td style=\"text-align: right;\">0.237683</td><td style=\"text-align: right;\">0.0564932</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210325_233034_model_8         </td><td style=\"text-align: right;\"> 0.214789</td><td style=\"text-align: right;\">0.838379</td><td style=\"text-align: right;\">0.560886</td><td style=\"text-align: right;\">              0.268278</td><td style=\"text-align: right;\">0.240495</td><td style=\"text-align: right;\">0.0578377</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210325_233034_model_12        </td><td style=\"text-align: right;\"> 0.214902</td><td style=\"text-align: right;\">0.843634</td><td style=\"text-align: right;\">0.579519</td><td style=\"text-align: right;\">              0.268258</td><td style=\"text-align: right;\">0.240877</td><td style=\"text-align: right;\">0.0580217</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210325_233034_model_3         </td><td style=\"text-align: right;\"> 0.216808</td><td style=\"text-align: right;\">0.836838</td><td style=\"text-align: right;\">0.559385</td><td style=\"text-align: right;\">              0.276243</td><td style=\"text-align: right;\">0.242068</td><td style=\"text-align: right;\">0.058597 </td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210325_233034_model_5         </td><td style=\"text-align: right;\"> 0.222949</td><td style=\"text-align: right;\">0.834869</td><td style=\"text-align: right;\">0.549111</td><td style=\"text-align: right;\">              0.278185</td><td style=\"text-align: right;\">0.246361</td><td style=\"text-align: right;\">0.0606937</td></tr>\n",
       "<tr><td>GLM_1_AutoML_20210325_233034                       </td><td style=\"text-align: right;\"> 0.287145</td><td style=\"text-align: right;\">0.658491</td><td style=\"text-align: right;\">0.148729</td><td style=\"text-align: right;\">              0.389841</td><td style=\"text-align: right;\">0.279866</td><td style=\"text-align: right;\">0.078325 </td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_20210325_233034              </td><td style=\"text-align: right;\"> 0.298261</td><td style=\"text-align: right;\">0.64279 </td><td style=\"text-align: right;\">0.16938 </td><td style=\"text-align: right;\">              0.402632</td><td style=\"text-align: right;\">0.283343</td><td style=\"text-align: right;\">0.0802832</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml = H2OAutoML(\n",
    "    max_runtime_secs=(3600 * 1),  # 1 hours\n",
    "    max_models=None,  # no limit\n",
    "    seed=17,\n",
    "    keep_cross_validation_predictions = True,\n",
    "    keep_cross_validation_fold_assignment = True,\n",
    "    sort_metric = \"logloss\"\n",
    ")\n",
    "aml.train(x=x, y=\"booked\", training_frame=X_y_train_h)\n",
    "lb = aml.leaderboard\n",
    "lb.head(rows=lb.nrows) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OStackedEnsembleEstimator :  Stacked Ensemble\n",
      "Model Key:  StackedEnsemble_AllModels_AutoML_20210325_233034\n",
      "\n",
      "No model summary for this model\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0005368551689642924\n",
      "RMSE: 0.02317013528152765\n",
      "LogLoss: 0.022166150584943124\n",
      "Null degrees of freedom: 10021\n",
      "Residual degrees of freedom: 10007\n",
      "Null deviance: 5812.106178792043\n",
      "Residual deviance: 444.2983223246001\n",
      "AIC: 474.2983223246001\n",
      "AUC: 1.0\n",
      "AUCPR: 1.0\n",
      "Gini: 1.0\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8189088918672589: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0/9174.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>848.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0/848.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>9174.0</td>\n",
       "      <td>848.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0/10022.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0      1 Error            Rate\n",
       "0      0  9174.0    0.0   0.0    (0.0/9174.0)\n",
       "1      1     0.0  848.0   0.0     (0.0/848.0)\n",
       "2  Total  9174.0  848.0   0.0   (0.0/10022.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.818909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.818909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.818909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.818909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.999263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.818909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.999263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.818909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.818909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.818909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.999263</td>\n",
       "      <td>9174.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.999263</td>\n",
       "      <td>838.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.015920</td>\n",
       "      <td>9174.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.818909</td>\n",
       "      <td>848.000000</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.999263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.999263</td>\n",
       "      <td>0.988208</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.015920</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.818909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold        value    idx\n",
       "0                        max f1   0.818909     1.000000  126.0\n",
       "1                        max f2   0.818909     1.000000  126.0\n",
       "2                  max f0point5   0.818909     1.000000  126.0\n",
       "3                  max accuracy   0.818909     1.000000  126.0\n",
       "4                 max precision   0.999263     1.000000    0.0\n",
       "5                    max recall   0.818909     1.000000  126.0\n",
       "6               max specificity   0.999263     1.000000    0.0\n",
       "7              max absolute_mcc   0.818909     1.000000  126.0\n",
       "8    max min_per_class_accuracy   0.818909     1.000000  126.0\n",
       "9   max mean_per_class_accuracy   0.818909     1.000000  126.0\n",
       "10                      max tns   0.999263  9174.000000    0.0\n",
       "11                      max fns   0.999263   838.000000    0.0\n",
       "12                      max fps   0.015920  9174.000000  399.0\n",
       "13                      max tps   0.818909   848.000000  126.0\n",
       "14                      max tnr   0.999263     1.000000    0.0\n",
       "15                      max fnr   0.999263     0.988208    0.0\n",
       "16                      max fpr   0.015920     1.000000  399.0\n",
       "17                      max tpr   0.818909     1.000000  126.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate:  8.46 %, avg score: 10.51 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010078</td>\n",
       "      <td>0.998709</td>\n",
       "      <td>11.818396</td>\n",
       "      <td>11.818396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998954</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998954</td>\n",
       "      <td>0.119104</td>\n",
       "      <td>0.119104</td>\n",
       "      <td>1081.839623</td>\n",
       "      <td>1081.839623</td>\n",
       "      <td>0.119104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020056</td>\n",
       "      <td>0.998133</td>\n",
       "      <td>11.818396</td>\n",
       "      <td>11.818396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>0.117925</td>\n",
       "      <td>0.237028</td>\n",
       "      <td>1081.839623</td>\n",
       "      <td>1081.839623</td>\n",
       "      <td>0.237028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030034</td>\n",
       "      <td>0.997715</td>\n",
       "      <td>11.818396</td>\n",
       "      <td>11.818396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998451</td>\n",
       "      <td>0.117925</td>\n",
       "      <td>0.354953</td>\n",
       "      <td>1081.839623</td>\n",
       "      <td>1081.839623</td>\n",
       "      <td>0.354953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040112</td>\n",
       "      <td>0.996854</td>\n",
       "      <td>11.818396</td>\n",
       "      <td>11.818396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998170</td>\n",
       "      <td>0.119104</td>\n",
       "      <td>0.474057</td>\n",
       "      <td>1081.839623</td>\n",
       "      <td>1081.839623</td>\n",
       "      <td>0.474057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050090</td>\n",
       "      <td>0.995746</td>\n",
       "      <td>11.818396</td>\n",
       "      <td>11.818396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997802</td>\n",
       "      <td>0.117925</td>\n",
       "      <td>0.591981</td>\n",
       "      <td>1081.839623</td>\n",
       "      <td>1081.839623</td>\n",
       "      <td>0.591981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100080</td>\n",
       "      <td>0.037612</td>\n",
       "      <td>8.162006</td>\n",
       "      <td>9.992024</td>\n",
       "      <td>0.690619</td>\n",
       "      <td>0.693187</td>\n",
       "      <td>0.845464</td>\n",
       "      <td>0.845646</td>\n",
       "      <td>0.408019</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>716.200618</td>\n",
       "      <td>899.202393</td>\n",
       "      <td>0.983104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150070</td>\n",
       "      <td>0.030802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.663564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033247</td>\n",
       "      <td>0.563830</td>\n",
       "      <td>0.575027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>566.356383</td>\n",
       "      <td>0.928494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200060</td>\n",
       "      <td>0.028154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.998504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029344</td>\n",
       "      <td>0.422943</td>\n",
       "      <td>0.438674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>399.850374</td>\n",
       "      <td>0.873883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300040</td>\n",
       "      <td>0.025511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.332890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026705</td>\n",
       "      <td>0.282009</td>\n",
       "      <td>0.301397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>233.288992</td>\n",
       "      <td>0.764661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.400020</td>\n",
       "      <td>0.023913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.499875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024683</td>\n",
       "      <td>0.211524</td>\n",
       "      <td>0.232236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>149.987528</td>\n",
       "      <td>0.655439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.022525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023188</td>\n",
       "      <td>0.169228</td>\n",
       "      <td>0.190434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.546218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.599980</td>\n",
       "      <td>0.021376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.666722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021943</td>\n",
       "      <td>0.141028</td>\n",
       "      <td>0.162357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>66.672210</td>\n",
       "      <td>0.436996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.700060</td>\n",
       "      <td>0.020356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.428449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020872</td>\n",
       "      <td>0.120867</td>\n",
       "      <td>0.142131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>42.844926</td>\n",
       "      <td>0.327665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799940</td>\n",
       "      <td>0.019396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.250094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019866</td>\n",
       "      <td>0.105775</td>\n",
       "      <td>0.126865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>25.009355</td>\n",
       "      <td>0.218552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899920</td>\n",
       "      <td>0.018369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.111210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.094024</td>\n",
       "      <td>0.114870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>11.120967</td>\n",
       "      <td>0.109331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017663</td>\n",
       "      <td>0.084614</td>\n",
       "      <td>0.105142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold       lift  \\\n",
       "0       1                  0.010078         0.998709  11.818396   \n",
       "1       2                  0.020056         0.998133  11.818396   \n",
       "2       3                  0.030034         0.997715  11.818396   \n",
       "3       4                  0.040112         0.996854  11.818396   \n",
       "4       5                  0.050090         0.995746  11.818396   \n",
       "5       6                  0.100080         0.037612   8.162006   \n",
       "6       7                  0.150070         0.030802   0.000000   \n",
       "7       8                  0.200060         0.028154   0.000000   \n",
       "8       9                  0.300040         0.025511   0.000000   \n",
       "9      10                  0.400020         0.023913   0.000000   \n",
       "10     11                  0.500000         0.022525   0.000000   \n",
       "11     12                  0.599980         0.021376   0.000000   \n",
       "12     13                  0.700060         0.020356   0.000000   \n",
       "13     14                  0.799940         0.019396   0.000000   \n",
       "14     15                  0.899920         0.018369   0.000000   \n",
       "15     16                  1.000000         0.015920   0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0         11.818396       1.000000  0.998954                  1.000000   \n",
       "1         11.818396       1.000000  0.998444                  1.000000   \n",
       "2         11.818396       1.000000  0.997949                  1.000000   \n",
       "3         11.818396       1.000000  0.997332                  1.000000   \n",
       "4         11.818396       1.000000  0.996326                  1.000000   \n",
       "5          9.992024       0.690619  0.693187                  0.845464   \n",
       "6          6.663564       0.000000  0.033247                  0.563830   \n",
       "7          4.998504       0.000000  0.029344                  0.422943   \n",
       "8          3.332890       0.000000  0.026705                  0.282009   \n",
       "9          2.499875       0.000000  0.024683                  0.211524   \n",
       "10         2.000000       0.000000  0.023188                  0.169228   \n",
       "11         1.666722       0.000000  0.021943                  0.141028   \n",
       "12         1.428449       0.000000  0.020872                  0.120867   \n",
       "13         1.250094       0.000000  0.019866                  0.105775   \n",
       "14         1.111210       0.000000  0.018900                  0.094024   \n",
       "15         1.000000       0.000000  0.017663                  0.084614   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate         gain  \\\n",
       "0           0.998954      0.119104                 0.119104  1081.839623   \n",
       "1           0.998700      0.117925                 0.237028  1081.839623   \n",
       "2           0.998451      0.117925                 0.354953  1081.839623   \n",
       "3           0.998170      0.119104                 0.474057  1081.839623   \n",
       "4           0.997802      0.117925                 0.591981  1081.839623   \n",
       "5           0.845646      0.408019                 1.000000   716.200618   \n",
       "6           0.575027      0.000000                 1.000000  -100.000000   \n",
       "7           0.438674      0.000000                 1.000000  -100.000000   \n",
       "8           0.301397      0.000000                 1.000000  -100.000000   \n",
       "9           0.232236      0.000000                 1.000000  -100.000000   \n",
       "10          0.190434      0.000000                 1.000000  -100.000000   \n",
       "11          0.162357      0.000000                 1.000000  -100.000000   \n",
       "12          0.142131      0.000000                 1.000000  -100.000000   \n",
       "13          0.126865      0.000000                 1.000000  -100.000000   \n",
       "14          0.114870      0.000000                 1.000000  -100.000000   \n",
       "15          0.105142      0.000000                 1.000000  -100.000000   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0       1081.839623            0.119104  \n",
       "1       1081.839623            0.237028  \n",
       "2       1081.839623            0.354953  \n",
       "3       1081.839623            0.474057  \n",
       "4       1081.839623            0.591981  \n",
       "5        899.202393            0.983104  \n",
       "6        566.356383            0.928494  \n",
       "7        399.850374            0.873883  \n",
       "8        233.288992            0.764661  \n",
       "9        149.987528            0.655439  \n",
       "10       100.000000            0.546218  \n",
       "11        66.672210            0.436996  \n",
       "12        42.844926            0.327665  \n",
       "13        25.009355            0.218552  \n",
       "14        11.120967            0.109331  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.02676693293075311\n",
      "RMSE: 0.16360602962835175\n",
      "LogLoss: 0.12184356012773448\n",
      "Null degrees of freedom: 24072\n",
      "Residual degrees of freedom: 24057\n",
      "Null deviance: 14340.964349605048\n",
      "Residual deviance: 5866.280045909904\n",
      "AIC: 5898.280045909904\n",
      "AUC: 0.8978592468197784\n",
      "AUCPR: 0.7876108232432837\n",
      "Gini: 0.7957184936395567\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8560870368835501: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21948.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>(7.0/21955.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>653.0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>0.3083</td>\n",
       "      <td>(653.0/2118.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>22601.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>(660.0/24073.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0       1   Error              Rate\n",
       "0      0  21948.0     7.0  0.0003     (7.0/21955.0)\n",
       "1      1    653.0  1465.0  0.3083    (653.0/2118.0)\n",
       "2  Total  22601.0  1472.0  0.0274   (660.0/24073.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.856087</td>\n",
       "      <td>0.816156</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.689671</td>\n",
       "      <td>0.736757</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.856087</td>\n",
       "      <td>0.914939</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.856087</td>\n",
       "      <td>0.972583</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.999059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.017145</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.999059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.856087</td>\n",
       "      <td>0.817379</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.032751</td>\n",
       "      <td>0.815392</td>\n",
       "      <td>297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.428413</td>\n",
       "      <td>0.845847</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.999059</td>\n",
       "      <td>21955.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.999059</td>\n",
       "      <td>2048.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.016648</td>\n",
       "      <td>21955.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.017145</td>\n",
       "      <td>2118.000000</td>\n",
       "      <td>397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.999059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.999059</td>\n",
       "      <td>0.966950</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.016648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.017145</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>397.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.856087      0.816156   81.0\n",
       "1                        max f2   0.689671      0.736757   86.0\n",
       "2                  max f0point5   0.856087      0.914939   81.0\n",
       "3                  max accuracy   0.856087      0.972583   81.0\n",
       "4                 max precision   0.999059      1.000000    0.0\n",
       "5                    max recall   0.017145      1.000000  397.0\n",
       "6               max specificity   0.999059      1.000000    0.0\n",
       "7              max absolute_mcc   0.856087      0.817379   81.0\n",
       "8    max min_per_class_accuracy   0.032751      0.815392  297.0\n",
       "9   max mean_per_class_accuracy   0.428413      0.845847  102.0\n",
       "10                      max tns   0.999059  21955.000000    0.0\n",
       "11                      max fns   0.999059   2048.000000    0.0\n",
       "12                      max fps   0.016648  21955.000000  399.0\n",
       "13                      max tps   0.017145   2118.000000  397.0\n",
       "14                      max tnr   0.999059      1.000000    0.0\n",
       "15                      max fnr   0.999059      0.966950    0.0\n",
       "16                      max fpr   0.016648      1.000000  399.0\n",
       "17                      max tpr   0.017145      1.000000  397.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate:  8.80 %, avg score:  8.80 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010011</td>\n",
       "      <td>0.997987</td>\n",
       "      <td>11.365911</td>\n",
       "      <td>11.365911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998640</td>\n",
       "      <td>0.113787</td>\n",
       "      <td>0.113787</td>\n",
       "      <td>1036.591124</td>\n",
       "      <td>1036.591124</td>\n",
       "      <td>0.113787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020022</td>\n",
       "      <td>0.996700</td>\n",
       "      <td>11.365911</td>\n",
       "      <td>11.365911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997436</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998038</td>\n",
       "      <td>0.113787</td>\n",
       "      <td>0.227573</td>\n",
       "      <td>1036.591124</td>\n",
       "      <td>1036.591124</td>\n",
       "      <td>0.227573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030034</td>\n",
       "      <td>0.994572</td>\n",
       "      <td>11.365911</td>\n",
       "      <td>11.365911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995739</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997272</td>\n",
       "      <td>0.113787</td>\n",
       "      <td>0.341360</td>\n",
       "      <td>1036.591124</td>\n",
       "      <td>1036.591124</td>\n",
       "      <td>0.341360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040003</td>\n",
       "      <td>0.990135</td>\n",
       "      <td>11.365911</td>\n",
       "      <td>11.365911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992394</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996056</td>\n",
       "      <td>0.113314</td>\n",
       "      <td>0.454674</td>\n",
       "      <td>1036.591124</td>\n",
       "      <td>1036.591124</td>\n",
       "      <td>0.454674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050015</td>\n",
       "      <td>0.981297</td>\n",
       "      <td>11.365911</td>\n",
       "      <td>11.365911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986214</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994086</td>\n",
       "      <td>0.113787</td>\n",
       "      <td>0.568461</td>\n",
       "      <td>1036.591124</td>\n",
       "      <td>1036.591124</td>\n",
       "      <td>0.568461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100029</td>\n",
       "      <td>0.054080</td>\n",
       "      <td>3.086921</td>\n",
       "      <td>7.226416</td>\n",
       "      <td>0.271595</td>\n",
       "      <td>0.292914</td>\n",
       "      <td>0.635797</td>\n",
       "      <td>0.643500</td>\n",
       "      <td>0.154391</td>\n",
       "      <td>0.722852</td>\n",
       "      <td>208.692108</td>\n",
       "      <td>622.641616</td>\n",
       "      <td>0.682906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150002</td>\n",
       "      <td>0.040489</td>\n",
       "      <td>0.746390</td>\n",
       "      <td>5.067604</td>\n",
       "      <td>0.065669</td>\n",
       "      <td>0.045765</td>\n",
       "      <td>0.445860</td>\n",
       "      <td>0.444365</td>\n",
       "      <td>0.037299</td>\n",
       "      <td>0.760151</td>\n",
       "      <td>-25.361015</td>\n",
       "      <td>406.760374</td>\n",
       "      <td>0.669010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200017</td>\n",
       "      <td>0.035010</td>\n",
       "      <td>0.698569</td>\n",
       "      <td>3.975118</td>\n",
       "      <td>0.061462</td>\n",
       "      <td>0.037428</td>\n",
       "      <td>0.349740</td>\n",
       "      <td>0.342610</td>\n",
       "      <td>0.034939</td>\n",
       "      <td>0.795090</td>\n",
       "      <td>-30.143070</td>\n",
       "      <td>297.511828</td>\n",
       "      <td>0.652480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300004</td>\n",
       "      <td>0.030029</td>\n",
       "      <td>0.462758</td>\n",
       "      <td>2.804494</td>\n",
       "      <td>0.040715</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.246746</td>\n",
       "      <td>0.239157</td>\n",
       "      <td>0.046270</td>\n",
       "      <td>0.841360</td>\n",
       "      <td>-53.724167</td>\n",
       "      <td>180.449374</td>\n",
       "      <td>0.593580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.027249</td>\n",
       "      <td>0.406094</td>\n",
       "      <td>2.204956</td>\n",
       "      <td>0.035729</td>\n",
       "      <td>0.028550</td>\n",
       "      <td>0.193997</td>\n",
       "      <td>0.186510</td>\n",
       "      <td>0.040604</td>\n",
       "      <td>0.881964</td>\n",
       "      <td>-59.390595</td>\n",
       "      <td>120.495609</td>\n",
       "      <td>0.528468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500021</td>\n",
       "      <td>0.025256</td>\n",
       "      <td>0.325684</td>\n",
       "      <td>1.829008</td>\n",
       "      <td>0.028654</td>\n",
       "      <td>0.026180</td>\n",
       "      <td>0.160920</td>\n",
       "      <td>0.154436</td>\n",
       "      <td>0.032578</td>\n",
       "      <td>0.914542</td>\n",
       "      <td>-67.431567</td>\n",
       "      <td>82.900806</td>\n",
       "      <td>0.454510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600008</td>\n",
       "      <td>0.023660</td>\n",
       "      <td>0.193603</td>\n",
       "      <td>1.556478</td>\n",
       "      <td>0.017034</td>\n",
       "      <td>0.024431</td>\n",
       "      <td>0.136943</td>\n",
       "      <td>0.132772</td>\n",
       "      <td>0.019358</td>\n",
       "      <td>0.933900</td>\n",
       "      <td>-80.639703</td>\n",
       "      <td>55.647829</td>\n",
       "      <td>0.366102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.699996</td>\n",
       "      <td>0.022266</td>\n",
       "      <td>0.188881</td>\n",
       "      <td>1.361130</td>\n",
       "      <td>0.016618</td>\n",
       "      <td>0.022960</td>\n",
       "      <td>0.119756</td>\n",
       "      <td>0.117086</td>\n",
       "      <td>0.018886</td>\n",
       "      <td>0.952786</td>\n",
       "      <td>-81.111905</td>\n",
       "      <td>36.113043</td>\n",
       "      <td>0.277176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799983</td>\n",
       "      <td>0.020919</td>\n",
       "      <td>0.174715</td>\n",
       "      <td>1.212844</td>\n",
       "      <td>0.015372</td>\n",
       "      <td>0.021596</td>\n",
       "      <td>0.106709</td>\n",
       "      <td>0.105151</td>\n",
       "      <td>0.017469</td>\n",
       "      <td>0.970255</td>\n",
       "      <td>-82.528512</td>\n",
       "      <td>21.284389</td>\n",
       "      <td>0.186698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899971</td>\n",
       "      <td>0.019488</td>\n",
       "      <td>0.132217</td>\n",
       "      <td>1.092785</td>\n",
       "      <td>0.011633</td>\n",
       "      <td>0.020245</td>\n",
       "      <td>0.096146</td>\n",
       "      <td>0.095718</td>\n",
       "      <td>0.013220</td>\n",
       "      <td>0.983475</td>\n",
       "      <td>-86.778333</td>\n",
       "      <td>9.278528</td>\n",
       "      <td>0.091560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016229</td>\n",
       "      <td>0.165202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014535</td>\n",
       "      <td>0.018474</td>\n",
       "      <td>0.087982</td>\n",
       "      <td>0.087991</td>\n",
       "      <td>0.016525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-83.479780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold       lift  \\\n",
       "0       1                  0.010011         0.997987  11.365911   \n",
       "1       2                  0.020022         0.996700  11.365911   \n",
       "2       3                  0.030034         0.994572  11.365911   \n",
       "3       4                  0.040003         0.990135  11.365911   \n",
       "4       5                  0.050015         0.981297  11.365911   \n",
       "5       6                  0.100029         0.054080   3.086921   \n",
       "6       7                  0.150002         0.040489   0.746390   \n",
       "7       8                  0.200017         0.035010   0.698569   \n",
       "8       9                  0.300004         0.030029   0.462758   \n",
       "9      10                  0.399992         0.027249   0.406094   \n",
       "10     11                  0.500021         0.025256   0.325684   \n",
       "11     12                  0.600008         0.023660   0.193603   \n",
       "12     13                  0.699996         0.022266   0.188881   \n",
       "13     14                  0.799983         0.020919   0.174715   \n",
       "14     15                  0.899971         0.019488   0.132217   \n",
       "15     16                  1.000000         0.016229   0.165202   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0         11.365911       1.000000  0.998640                  1.000000   \n",
       "1         11.365911       1.000000  0.997436                  1.000000   \n",
       "2         11.365911       1.000000  0.995739                  1.000000   \n",
       "3         11.365911       1.000000  0.992394                  1.000000   \n",
       "4         11.365911       1.000000  0.986214                  1.000000   \n",
       "5          7.226416       0.271595  0.292914                  0.635797   \n",
       "6          5.067604       0.065669  0.045765                  0.445860   \n",
       "7          3.975118       0.061462  0.037428                  0.349740   \n",
       "8          2.804494       0.040715  0.032207                  0.246746   \n",
       "9          2.204956       0.035729  0.028550                  0.193997   \n",
       "10         1.829008       0.028654  0.026180                  0.160920   \n",
       "11         1.556478       0.017034  0.024431                  0.136943   \n",
       "12         1.361130       0.016618  0.022960                  0.119756   \n",
       "13         1.212844       0.015372  0.021596                  0.106709   \n",
       "14         1.092785       0.011633  0.020245                  0.096146   \n",
       "15         1.000000       0.014535  0.018474                  0.087982   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate         gain  \\\n",
       "0           0.998640      0.113787                 0.113787  1036.591124   \n",
       "1           0.998038      0.113787                 0.227573  1036.591124   \n",
       "2           0.997272      0.113787                 0.341360  1036.591124   \n",
       "3           0.996056      0.113314                 0.454674  1036.591124   \n",
       "4           0.994086      0.113787                 0.568461  1036.591124   \n",
       "5           0.643500      0.154391                 0.722852   208.692108   \n",
       "6           0.444365      0.037299                 0.760151   -25.361015   \n",
       "7           0.342610      0.034939                 0.795090   -30.143070   \n",
       "8           0.239157      0.046270                 0.841360   -53.724167   \n",
       "9           0.186510      0.040604                 0.881964   -59.390595   \n",
       "10          0.154436      0.032578                 0.914542   -67.431567   \n",
       "11          0.132772      0.019358                 0.933900   -80.639703   \n",
       "12          0.117086      0.018886                 0.952786   -81.111905   \n",
       "13          0.105151      0.017469                 0.970255   -82.528512   \n",
       "14          0.095718      0.013220                 0.983475   -86.778333   \n",
       "15          0.087991      0.016525                 1.000000   -83.479780   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0       1036.591124            0.113787  \n",
       "1       1036.591124            0.227573  \n",
       "2       1036.591124            0.341360  \n",
       "3       1036.591124            0.454674  \n",
       "4       1036.591124            0.568461  \n",
       "5        622.641616            0.682906  \n",
       "6        406.760374            0.669010  \n",
       "7        297.511828            0.652480  \n",
       "8        180.449374            0.593580  \n",
       "9        120.495609            0.528468  \n",
       "10        82.900806            0.454510  \n",
       "11        55.647829            0.366102  \n",
       "12        36.113043            0.277176  \n",
       "13        21.284389            0.186698  \n",
       "14         9.278528            0.091560  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: || 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">      p0</th><th style=\"text-align: right;\">       p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.965465</td><td style=\"text-align: right;\">0.034535 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.967733</td><td style=\"text-align: right;\">0.0322666</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.977654</td><td style=\"text-align: right;\">0.0223456</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.972699</td><td style=\"text-align: right;\">0.0273013</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.976422</td><td style=\"text-align: right;\">0.023578 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.97845 </td><td style=\"text-align: right;\">0.0215496</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.976382</td><td style=\"text-align: right;\">0.0236184</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.973544</td><td style=\"text-align: right;\">0.0264562</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.974935</td><td style=\"text-align: right;\">0.0250654</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.969201</td><td style=\"text-align: right;\">0.0307992</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader.predict(X_test_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2O Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.07783281807207904\n",
      "RMSE: 0.2789853366614078\n",
      "LogLoss: 0.3074674883972936\n",
      "Null degrees of freedom: 14004\n",
      "Residual degrees of freedom: 13990\n",
      "Null deviance: 8210.770859191129\n",
      "Residual deviance: 8612.164350008194\n",
      "AIC: 8642.164350008194\n",
      "AUC: 0.6513625648536076\n",
      "AUCPR: 0.19818073282532578\n",
      "Gini: 0.3027251297072151\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.039612118937822995: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10841.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>0.1531</td>\n",
       "      <td>(1960.0/12801.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>791.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>0.657</td>\n",
       "      <td>(791.0/1204.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>11632.0</td>\n",
       "      <td>2373.0</td>\n",
       "      <td>0.1964</td>\n",
       "      <td>(2751.0/14005.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0       1   Error               Rate\n",
       "0      0  10841.0  1960.0  0.1531   (1960.0/12801.0)\n",
       "1      1    791.0   413.0   0.657     (791.0/1204.0)\n",
       "2  Total  11632.0  2373.0  0.1964   (2751.0/14005.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.039612</td>\n",
       "      <td>0.230920</td>\n",
       "      <td>234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.027797</td>\n",
       "      <td>0.352319</td>\n",
       "      <td>311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.069637</td>\n",
       "      <td>0.245828</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.575280</td>\n",
       "      <td>0.916887</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.997465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.017272</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.997465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.575280</td>\n",
       "      <td>0.173824</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.029013</td>\n",
       "      <td>0.609484</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.029113</td>\n",
       "      <td>0.610398</td>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.997465</td>\n",
       "      <td>12801.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.997465</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.016031</td>\n",
       "      <td>12801.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.017272</td>\n",
       "      <td>1204.000000</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.997465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.997465</td>\n",
       "      <td>0.993355</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.016031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.017272</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.039612      0.230920  234.0\n",
       "1                        max f2   0.027797      0.352319  311.0\n",
       "2                  max f0point5   0.069637      0.245828  145.0\n",
       "3                  max accuracy   0.575280      0.916887   20.0\n",
       "4                 max precision   0.997465      1.000000    0.0\n",
       "5                    max recall   0.017272      1.000000  395.0\n",
       "6               max specificity   0.997465      1.000000    0.0\n",
       "7              max absolute_mcc   0.575280      0.173824   20.0\n",
       "8    max min_per_class_accuracy   0.029013      0.609484  300.0\n",
       "9   max mean_per_class_accuracy   0.029113      0.610398  299.0\n",
       "10                      max tns   0.997465  12801.000000    0.0\n",
       "11                      max fns   0.997465   1196.000000    0.0\n",
       "12                      max fps   0.016031  12801.000000  399.0\n",
       "13                      max tps   0.017272   1204.000000  395.0\n",
       "14                      max tnr   0.997465      1.000000    0.0\n",
       "15                      max fnr   0.997465      0.993355    0.0\n",
       "16                      max fpr   0.016031      1.000000  399.0\n",
       "17                      max tpr   0.017272      1.000000  395.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate:  8.60 %, avg score:  3.52 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010211</td>\n",
       "      <td>0.148799</td>\n",
       "      <td>5.612672</td>\n",
       "      <td>5.612672</td>\n",
       "      <td>0.482517</td>\n",
       "      <td>0.454051</td>\n",
       "      <td>0.482517</td>\n",
       "      <td>0.454051</td>\n",
       "      <td>0.057309</td>\n",
       "      <td>0.057309</td>\n",
       "      <td>461.267221</td>\n",
       "      <td>461.267221</td>\n",
       "      <td>0.051528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020136</td>\n",
       "      <td>0.094966</td>\n",
       "      <td>2.677884</td>\n",
       "      <td>4.166092</td>\n",
       "      <td>0.230216</td>\n",
       "      <td>0.116263</td>\n",
       "      <td>0.358156</td>\n",
       "      <td>0.287553</td>\n",
       "      <td>0.026578</td>\n",
       "      <td>0.083887</td>\n",
       "      <td>167.788427</td>\n",
       "      <td>316.609234</td>\n",
       "      <td>0.069748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030132</td>\n",
       "      <td>0.076641</td>\n",
       "      <td>2.409498</td>\n",
       "      <td>3.583336</td>\n",
       "      <td>0.207143</td>\n",
       "      <td>0.084829</td>\n",
       "      <td>0.308057</td>\n",
       "      <td>0.220298</td>\n",
       "      <td>0.024086</td>\n",
       "      <td>0.107973</td>\n",
       "      <td>140.949810</td>\n",
       "      <td>258.333596</td>\n",
       "      <td>0.085163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040057</td>\n",
       "      <td>0.067508</td>\n",
       "      <td>2.928936</td>\n",
       "      <td>3.421194</td>\n",
       "      <td>0.251799</td>\n",
       "      <td>0.072334</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.183637</td>\n",
       "      <td>0.029070</td>\n",
       "      <td>0.137043</td>\n",
       "      <td>192.893592</td>\n",
       "      <td>242.119406</td>\n",
       "      <td>0.106108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050196</td>\n",
       "      <td>0.062006</td>\n",
       "      <td>1.802150</td>\n",
       "      <td>3.094161</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>0.064457</td>\n",
       "      <td>0.266003</td>\n",
       "      <td>0.159564</td>\n",
       "      <td>0.018272</td>\n",
       "      <td>0.155316</td>\n",
       "      <td>80.215011</td>\n",
       "      <td>209.416100</td>\n",
       "      <td>0.115006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100036</td>\n",
       "      <td>0.047352</td>\n",
       "      <td>1.383182</td>\n",
       "      <td>2.241725</td>\n",
       "      <td>0.118911</td>\n",
       "      <td>0.053111</td>\n",
       "      <td>0.192719</td>\n",
       "      <td>0.106527</td>\n",
       "      <td>0.068937</td>\n",
       "      <td>0.224252</td>\n",
       "      <td>38.318190</td>\n",
       "      <td>124.172459</td>\n",
       "      <td>0.135900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150018</td>\n",
       "      <td>0.041266</td>\n",
       "      <td>1.628488</td>\n",
       "      <td>2.037410</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.044107</td>\n",
       "      <td>0.175155</td>\n",
       "      <td>0.085730</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.305648</td>\n",
       "      <td>62.848837</td>\n",
       "      <td>103.740981</td>\n",
       "      <td>0.170268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200071</td>\n",
       "      <td>0.037283</td>\n",
       "      <td>1.410449</td>\n",
       "      <td>1.880558</td>\n",
       "      <td>0.121255</td>\n",
       "      <td>0.039083</td>\n",
       "      <td>0.161670</td>\n",
       "      <td>0.074060</td>\n",
       "      <td>0.070598</td>\n",
       "      <td>0.376246</td>\n",
       "      <td>41.044948</td>\n",
       "      <td>88.055785</td>\n",
       "      <td>0.192745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300036</td>\n",
       "      <td>0.032472</td>\n",
       "      <td>1.163206</td>\n",
       "      <td>1.641554</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.034670</td>\n",
       "      <td>0.141123</td>\n",
       "      <td>0.060936</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.492525</td>\n",
       "      <td>16.320598</td>\n",
       "      <td>64.155437</td>\n",
       "      <td>0.210594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.029186</td>\n",
       "      <td>1.096737</td>\n",
       "      <td>1.505399</td>\n",
       "      <td>0.094286</td>\n",
       "      <td>0.030736</td>\n",
       "      <td>0.129418</td>\n",
       "      <td>0.053389</td>\n",
       "      <td>0.109635</td>\n",
       "      <td>0.602159</td>\n",
       "      <td>9.673707</td>\n",
       "      <td>50.539867</td>\n",
       "      <td>0.221174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500036</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.747242</td>\n",
       "      <td>1.353724</td>\n",
       "      <td>0.064240</td>\n",
       "      <td>0.027944</td>\n",
       "      <td>0.116379</td>\n",
       "      <td>0.048299</td>\n",
       "      <td>0.074751</td>\n",
       "      <td>0.676910</td>\n",
       "      <td>-25.275847</td>\n",
       "      <td>35.372394</td>\n",
       "      <td>0.193511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600071</td>\n",
       "      <td>0.024805</td>\n",
       "      <td>0.788755</td>\n",
       "      <td>1.259540</td>\n",
       "      <td>0.067809</td>\n",
       "      <td>0.025751</td>\n",
       "      <td>0.108282</td>\n",
       "      <td>0.044540</td>\n",
       "      <td>0.078904</td>\n",
       "      <td>0.755814</td>\n",
       "      <td>-21.124505</td>\n",
       "      <td>25.954003</td>\n",
       "      <td>0.170391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.699964</td>\n",
       "      <td>0.023042</td>\n",
       "      <td>0.814826</td>\n",
       "      <td>1.196074</td>\n",
       "      <td>0.070050</td>\n",
       "      <td>0.023907</td>\n",
       "      <td>0.102826</td>\n",
       "      <td>0.041595</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>-18.517380</td>\n",
       "      <td>19.607429</td>\n",
       "      <td>0.150154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.021369</td>\n",
       "      <td>0.747242</td>\n",
       "      <td>1.139950</td>\n",
       "      <td>0.064240</td>\n",
       "      <td>0.022188</td>\n",
       "      <td>0.098001</td>\n",
       "      <td>0.039169</td>\n",
       "      <td>0.074751</td>\n",
       "      <td>0.911960</td>\n",
       "      <td>-25.275847</td>\n",
       "      <td>13.995017</td>\n",
       "      <td>0.122491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899964</td>\n",
       "      <td>0.019691</td>\n",
       "      <td>0.540060</td>\n",
       "      <td>1.073317</td>\n",
       "      <td>0.046429</td>\n",
       "      <td>0.020564</td>\n",
       "      <td>0.092272</td>\n",
       "      <td>0.037102</td>\n",
       "      <td>0.053987</td>\n",
       "      <td>0.965947</td>\n",
       "      <td>-45.994008</td>\n",
       "      <td>7.331685</td>\n",
       "      <td>0.072189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015875</td>\n",
       "      <td>0.340410</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029265</td>\n",
       "      <td>0.018530</td>\n",
       "      <td>0.085969</td>\n",
       "      <td>0.035244</td>\n",
       "      <td>0.034053</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-65.958997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010211         0.148799  5.612672   \n",
       "1       2                  0.020136         0.094966  2.677884   \n",
       "2       3                  0.030132         0.076641  2.409498   \n",
       "3       4                  0.040057         0.067508  2.928936   \n",
       "4       5                  0.050196         0.062006  1.802150   \n",
       "5       6                  0.100036         0.047352  1.383182   \n",
       "6       7                  0.150018         0.041266  1.628488   \n",
       "7       8                  0.200071         0.037283  1.410449   \n",
       "8       9                  0.300036         0.032472  1.163206   \n",
       "9      10                  0.400000         0.029186  1.096737   \n",
       "10     11                  0.500036         0.026735  0.747242   \n",
       "11     12                  0.600071         0.024805  0.788755   \n",
       "12     13                  0.699964         0.023042  0.814826   \n",
       "13     14                  0.800000         0.021369  0.747242   \n",
       "14     15                  0.899964         0.019691  0.540060   \n",
       "15     16                  1.000000         0.015875  0.340410   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          5.612672       0.482517  0.454051                  0.482517   \n",
       "1          4.166092       0.230216  0.116263                  0.358156   \n",
       "2          3.583336       0.207143  0.084829                  0.308057   \n",
       "3          3.421194       0.251799  0.072334                  0.294118   \n",
       "4          3.094161       0.154930  0.064457                  0.266003   \n",
       "5          2.241725       0.118911  0.053111                  0.192719   \n",
       "6          2.037410       0.140000  0.044107                  0.175155   \n",
       "7          1.880558       0.121255  0.039083                  0.161670   \n",
       "8          1.641554       0.100000  0.034670                  0.141123   \n",
       "9          1.505399       0.094286  0.030736                  0.129418   \n",
       "10         1.353724       0.064240  0.027944                  0.116379   \n",
       "11         1.259540       0.067809  0.025751                  0.108282   \n",
       "12         1.196074       0.070050  0.023907                  0.102826   \n",
       "13         1.139950       0.064240  0.022188                  0.098001   \n",
       "14         1.073317       0.046429  0.020564                  0.092272   \n",
       "15         1.000000       0.029265  0.018530                  0.085969   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.454051      0.057309                 0.057309  461.267221   \n",
       "1           0.287553      0.026578                 0.083887  167.788427   \n",
       "2           0.220298      0.024086                 0.107973  140.949810   \n",
       "3           0.183637      0.029070                 0.137043  192.893592   \n",
       "4           0.159564      0.018272                 0.155316   80.215011   \n",
       "5           0.106527      0.068937                 0.224252   38.318190   \n",
       "6           0.085730      0.081395                 0.305648   62.848837   \n",
       "7           0.074060      0.070598                 0.376246   41.044948   \n",
       "8           0.060936      0.116279                 0.492525   16.320598   \n",
       "9           0.053389      0.109635                 0.602159    9.673707   \n",
       "10          0.048299      0.074751                 0.676910  -25.275847   \n",
       "11          0.044540      0.078904                 0.755814  -21.124505   \n",
       "12          0.041595      0.081395                 0.837209  -18.517380   \n",
       "13          0.039169      0.074751                 0.911960  -25.275847   \n",
       "14          0.037102      0.053987                 0.965947  -45.994008   \n",
       "15          0.035244      0.034053                 1.000000  -65.958997   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        461.267221            0.051528  \n",
       "1        316.609234            0.069748  \n",
       "2        258.333596            0.085163  \n",
       "3        242.119406            0.106108  \n",
       "4        209.416100            0.115006  \n",
       "5        124.172459            0.135900  \n",
       "6        103.740981            0.170268  \n",
       "7         88.055785            0.192745  \n",
       "8         64.155437            0.210594  \n",
       "9         50.539867            0.221174  \n",
       "10        35.372394            0.193511  \n",
       "11        25.954003            0.170391  \n",
       "12        19.607429            0.150154  \n",
       "13        13.995017            0.122491  \n",
       "14         7.331685            0.072189  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader.model_performance(X_y_test_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.save_model(aml.leader, path = \"./search_ranking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shallow Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4149,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model(units, optimizer):\n",
    "    model8 = models.Sequential()\n",
    "    model8.add(layers.Dense(units, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model8.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model8.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[metrics.AUC(name='auc')])\n",
    "\n",
    "    class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "\n",
    "    history = model8.fit(X_train, y_train, batch_size=300, epochs=80, verbose=0, class_weight={0:class_weights[0], 1:class_weights[1]})\n",
    "                      #callbacks=[EarlyStopping(monitor='auc',min_delta=0.1)])\n",
    "    return max(history.history['auc'])\n",
    "auc_score = get_model(64, 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred8 = model8.predict(X_test)\n",
    "y_pred8 =(y_pred8 >= 0.5)\n",
    "\n",
    "confusion_Matrix = pd.DataFrame(\n",
    "        confusion_matrix(y_test, y_pred8),\n",
    "        columns=['Predicted As No', 'Predicted As Yes'],\n",
    "        index=['True No', 'True Yes'])\n",
    "\n",
    "print(classification_report(y_test, y_pred8))\n",
    "print(confusion_Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Ranking Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final stage I will create a ranking table that can be used to claculate the NDCG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'probility':y_pred1,'booked':booked_list,'clicked':clicked_list, 'contacted': contacted_list, 'id_search': srchid_list})\n",
    "result['position'] = 0\n",
    "result = result.reset_index(0, drop=True)\n",
    "result['score'] = result['clicked']*1 + result['contacted']*3 + result['booked']*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = result.groupby('id_search', group_keys=False).apply(lambda x: x.sort_values('probility', ascending=False))\n",
    "rank_order = rank.groupby('id_search').head(6).reset_index(drop=True)\n",
    "rank_order['position'] = rank_order.groupby(['id_search'])['position'].rank(method='first').astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndgc_input = rank_order.pivot(index='id_search', columns='position', values='score').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Ranking Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(r, k, method=0):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "     \n",
    "    else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "\n",
    "def ndcg_at_k(r, k, method=0):\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndgc_input['ndcg'] = ndgc_input.iloc[:,1:].apply(lambda x: ndcg_at_k(x, 6), axis=1)\n",
    "score = ndgc_input['ndcg'].mean()\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# New Listings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New listings are negatively correlated to the label.\n",
    "correlations['listing_is_new'] = -0.027\n",
    "\n",
    "There could be multiple approaches to overcome the problem of new listings being underanked, for example looking at the textual information of the listings, such as title, description, amenities \n",
    "and calculate similarities to the users' historic infomation (reviews, information about properties where user stayed and gave a high rating).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Conclusions and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the  model is optimized for production, it should be able to quickly rank the listings-candate in the \n",
    "specific search area according to the probability of booking. If there are too many candidates, first step could be an efficient candidate generation model with focus on high recall and the ranking step on higher precision.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Utilize all actions not only booked for multiclass classification problem to predict the probability of booking. The resulting probabilities could be weighted according to their importance before the final probability if being calculated.\n",
    "2. Enrich data set with historic user information about his previous actions.\n",
    "3. Enrich data with geo information by utilizing the reverse geocoding or geohashes as neighbohoord information may play an important role in users decision to book.\n",
    "4. Enrich data with historic information of the listings (number of clicked in the last week, month, number of contacts with host)\n",
    "4. Enrich data with temporal information, such as holidays, seasonalty, events, trends.\n",
    "5. Consider processing textual information from user reviews and listing reviews and calculating similarities.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
